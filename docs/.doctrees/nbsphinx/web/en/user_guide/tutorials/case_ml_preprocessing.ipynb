{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Preprocessing Pipeline\n",
    "\n",
    "The `MLPreprocessor` class provides a scikit-learn-style transformer API for preprocessing gravitational-wave data for machine learning applications. It implements the preprocessing pipeline used in DeepClean v2, including:\n",
    "\n",
    "- **Data splitting**: Time-ordered train/validation split with integer-second alignment\n",
    "- **Bandpass filtering**: Butterworth filter with multiple frequency bands\n",
    "- **Standardization**: Channel-wise normalization (Z-score or robust MAD-based)\n",
    "\n",
    "This preprocessing is applicable to any machine learning model (DeepClean, Random Forest, XGBoost, etc.), not just deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the root directory is in sys.path\n",
    "root = Path.cwd()\n",
    "while root.parent != root:\n",
    "    if (root / \"gwexpy\").exists():\n",
    "        if str(root) not in sys.path:\n",
    "            sys.path.insert(0, str(root))\n",
    "        break\n",
    "    root = root.parent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from gwexpy.signal.preprocessing import MLPreprocessor\n",
    "from gwexpy.timeseries import TimeSeries, TimeSeriesMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "Let's create some dummy data representing auxiliary (witness) channels and a target strain channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "np.random.seed(42)\n",
    "sample_rate = 4096  # Hz\n",
    "duration = 10  # seconds\n",
    "n_samples = sample_rate * duration\n",
    "n_channels = 3\n",
    "\n",
    "# Witness channels (auxiliary sensors)\n",
    "witnesses = TimeSeriesMatrix(\n",
    "    np.random.randn(n_channels, n_samples) * 10 + 50,  # Different mean/std\n",
    "    t0=0,\n",
    "    dt=1 / sample_rate,\n",
    "    unit=\"m/s^2\",\n",
    "    channel_names=[\"SEIS-X\", \"SEIS-Y\", \"SEIS-Z\"],\n",
    ")\n",
    "\n",
    "# Target strain channel with 60Hz noise\n",
    "t = np.arange(n_samples) / sample_rate\n",
    "signal_60hz = 2 * np.sin(2 * np.pi * 60 * t)\n",
    "strain = TimeSeries(\n",
    "    signal_60hz + np.random.randn(n_samples) * 0.5,\n",
    "    t0=0,\n",
    "    dt=1 / sample_rate,\n",
    "    unit=\"strain\",\n",
    "    name=\"H1:GDS-CALIB_STRAIN\",\n",
    ")\n",
    "\n",
    "print(f\"Witnesses shape: {witnesses.shape}\")\n",
    "print(f\"Strain length: {len(strain)}\")\n",
    "print(f\"Duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline\n",
    "\n",
    "The typical workflow is:\n",
    "1. **split()**: Divide data into train/validation sets\n",
    "2. **fit()**: Learn statistics and filter coefficients from training data\n",
    "3. **transform()**: Apply preprocessing to train/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessor with 55-65 Hz bandpass filter\n",
    "preprocessor = MLPreprocessor(\n",
    "    sample_rate=sample_rate,\n",
    "    freq_low=[55.0],\n",
    "    freq_high=[65.0],\n",
    "    valid_frac=0.2,  # 20% validation\n",
    "    standardization_method=\"zscore\",\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, y_train, X_valid, y_valid = preprocessor.split(witnesses, strain)\n",
    "\n",
    "print(f\"Training samples: {len(y_train)} ({len(y_train)/sample_rate:.1f}s)\")\n",
    "print(f\"Validation samples: {len(y_valid)} ({len(y_valid)/sample_rate:.1f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training data\n",
    "preprocessor.fit(X_train, y_train)\n",
    "\n",
    "# Transform both train and validation\n",
    "X_train_proc, y_train_proc = preprocessor.transform(X_train, y_train)\n",
    "X_valid_proc, y_valid_proc = preprocessor.transform(X_valid, y_valid)\n",
    "\n",
    "print(f\"Processed train X shape: {X_train_proc.shape}\")\n",
    "print(f\"Processed train y length: {len(y_train_proc)}\")\n",
    "print(f\"Output units: X={X_train_proc.units[0,0]}, y={y_train_proc.unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting Visualization\n",
    "\n",
    "The split is time-ordered (first portion for training, last for validation) with integer-second alignment to match DeepClean v2 behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Plot original strain\n",
    "axes[0].plot(strain.times.value, strain.value, alpha=0.7, label=\"Original\")\n",
    "axes[0].axvline(\n",
    "    y_train.t0.value + len(y_train) * y_train.dt.value,\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Train/Valid split\",\n",
    ")\n",
    "axes[0].set_ylabel(\"Strain\")\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"Data Splitting (Time-Ordered)\")\n",
    "\n",
    "# Plot split data\n",
    "axes[1].plot(\n",
    "    y_train.times.value, y_train.value, label=\"Training data\", alpha=0.7, color=\"C0\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    y_valid.times.value, y_valid.value, label=\"Validation data\", alpha=0.7, color=\"C1\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Strain\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Standardization Effects\n",
    "\n",
    "**Important**: \n",
    "- **Witness channels (X)** are NOT filtered, only standardized\n",
    "- **Target channel (y)** is filtered THEN standardized\n",
    "\n",
    "This follows DeepClean v2's processing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Original witness channel (first 2 seconds)\n",
    "time_mask = X_train.times.value < 2\n",
    "axes[0, 0].plot(X_train.times.value[time_mask], X_train.value[0, 0, time_mask])\n",
    "axes[0, 0].set_title(\"Witness (Original)\")\n",
    "axes[0, 0].set_ylabel(f\"Amplitude ({X_train.units[0,0]})\")\n",
    "axes[0, 0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "# Standardized witness (NO filtering)\n",
    "axes[0, 1].plot(X_train_proc.times.value[time_mask], X_train_proc.value[0, 0, time_mask])\n",
    "axes[0, 1].set_title(\"Witness (Standardized, No Filter)\")\n",
    "axes[0, 1].set_ylabel(\"Normalized amplitude\")\n",
    "axes[0, 1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "# Original target\n",
    "axes[1, 0].plot(y_train.times.value[time_mask[:len(y_train)]], y_train.value[time_mask[:len(y_train)]])\n",
    "axes[1, 0].set_title(\"Target (Original)\")\n",
    "axes[1, 0].set_ylabel(f\"Amplitude ({y_train.unit})\")\n",
    "axes[1, 0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "# Filtered + standardized target\n",
    "axes[1, 1].plot(y_train_proc.times.value[time_mask[:len(y_train_proc)]], y_train_proc.value[time_mask[:len(y_train_proc)]])\n",
    "axes[1, 1].set_title(\"Target (55-65 Hz Filtered + Standardized)\")\n",
    "axes[1, 1].set_ylabel(\"Normalized amplitude\")\n",
    "axes[1, 1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Domain Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PSDs\n",
    "fft_length = 4  # seconds\n",
    "psd_original = y_train.psd(fftlength=fft_length)\n",
    "psd_filtered = y_train_proc.psd(fftlength=fft_length)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.loglog(psd_original.frequencies.value, psd_original.value, label=\"Original\", alpha=0.7)\n",
    "plt.loglog(psd_filtered.frequencies.value, psd_filtered.value, label=\"Filtered (55-65 Hz)\", alpha=0.7)\n",
    "plt.axvspan(55, 65, alpha=0.2, color=\"green\", label=\"Filter band\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.title(\"Effect of Bandpass Filtering\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", alpha=0.3)\n",
    "plt.xlim(10, 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Integration\n",
    "\n",
    "The preprocessed data can be used with `TimeSeriesWindowDataset` for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from gwexpy.interop import TimeSeriesWindowDataset\n",
    "    import torch\n",
    "\n",
    "    # Create dataset with 8-second windows, 0.0625-second stride\n",
    "    train_dataset = TimeSeriesWindowDataset(\n",
    "        X_train_proc,\n",
    "        labels=y_train_proc,\n",
    "        window=8 * sample_rate,\n",
    "        stride=int(0.0625 * sample_rate),\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset size: {len(train_dataset)} windows\")\n",
    "\n",
    "    # Get a batch\n",
    "    x_batch, y_batch = train_dataset[0]\n",
    "    print(f\"Batch shapes: X={x_batch.shape}, y={y_batch.shape}\")\n",
    "    print(f\"X dtype: {x_batch.dtype}\")\n",
    "    print(f\"y dtype: {y_batch.dtype}\")\n",
    "\n",
    "    # Create DataLoader\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    print(f\"\\nDataLoader created with {len(train_loader)} batches\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"PyTorch integration skipped: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Topics\n",
    "\n",
    "### Multiple Frequency Bands\n",
    "\n",
    "You can filter multiple frequency bands simultaneously (results are summed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 120 Hz noise to original data\n",
    "signal_120hz = 1.5 * np.sin(2 * np.pi * 120 * t)\n",
    "strain_multi = TimeSeries(\n",
    "    signal_60hz + signal_120hz + np.random.randn(n_samples) * 0.5,\n",
    "    t0=0,\n",
    "    dt=1 / sample_rate,\n",
    "    unit=\"strain\",\n",
    ")\n",
    "\n",
    "# Preprocessor with two bands\n",
    "preprocessor_multi = MLPreprocessor(\n",
    "    sample_rate=sample_rate,\n",
    "    freq_low=[55.0, 110.0],  # Two bands\n",
    "    freq_high=[65.0, 125.0],\n",
    "    valid_frac=0.2,\n",
    ")\n",
    "\n",
    "X_train_m, y_train_m, X_valid_m, y_valid_m = preprocessor_multi.split(\n",
    "    witnesses, strain_multi\n",
    ")\n",
    "preprocessor_multi.fit(X_train_m, y_train_m)\n",
    "_, y_train_multi_proc = preprocessor_multi.transform(X_train_m, y_train_m)\n",
    "\n",
    "print(f\"Number of filter bands: {len(preprocessor_multi.filter_coeffs_)}\")\n",
    "\n",
    "# Compare PSDs\n",
    "psd_multi_orig = y_train_m.psd(fftlength=4)\n",
    "psd_multi_filt = y_train_multi_proc.psd(fftlength=4)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.loglog(psd_multi_orig.frequencies.value, psd_multi_orig.value, label=\"Original\", alpha=0.7)\n",
    "plt.loglog(psd_multi_filt.frequencies.value, psd_multi_filt.value, label=\"Filtered (2 bands)\", alpha=0.7)\n",
    "plt.axvspan(55, 65, alpha=0.2, color=\"green\", label=\"Band 1\")\n",
    "plt.axvspan(110, 125, alpha=0.2, color=\"orange\", label=\"Band 2\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.title(\"Multi-Band Filtering\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", alpha=0.3)\n",
    "plt.xlim(10, 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Standardization\n",
    "\n",
    "For data with outliers, use `robust` (MAD-based) standardization instead of z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with outliers\n",
    "np.random.seed(0)\n",
    "data_with_outliers = np.random.randn(n_channels, n_samples)\n",
    "data_with_outliers[0, 1000:1010] = 100  # Inject outliers\n",
    "witnesses_outliers = TimeSeriesMatrix(\n",
    "    data_with_outliers, t0=0, dt=1 / sample_rate, unit=\"m/s^2\"\n",
    ")\n",
    "\n",
    "# Compare z-score vs robust\n",
    "prep_zscore = MLPreprocessor(sample_rate=sample_rate, standardization_method=\"zscore\")\n",
    "prep_robust = MLPreprocessor(sample_rate=sample_rate, standardization_method=\"robust\")\n",
    "\n",
    "prep_zscore.fit(witnesses_outliers, y=None)\n",
    "prep_robust.fit(witnesses_outliers, y=None)\n",
    "\n",
    "X_zscore = prep_zscore.transform(witnesses_outliers, y=None)\n",
    "X_robust = prep_robust.transform(witnesses_outliers, y=None)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "time_window = slice(0, 2 * sample_rate)  # First 2 seconds\n",
    "times = witnesses_outliers.times.value[time_window]\n",
    "\n",
    "axes[0].plot(times, witnesses_outliers.value[0, 0, time_window])\n",
    "axes[0].set_title(\"Original (with outliers at t~0.24s)\")\n",
    "axes[0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "axes[1].plot(times, X_zscore.value[0, 0, time_window])\n",
    "axes[1].set_title(\"Z-score standardization (sensitive to outliers)\")\n",
    "axes[1].set_ylabel(\"Normalized\")\n",
    "\n",
    "axes[2].plot(times, X_robust.value[0, 0, time_window])\n",
    "axes[2].set_title(\"Robust (MAD) standardization (resistant to outliers)\")\n",
    "axes[2].set_ylabel(\"Normalized\")\n",
    "axes[2].set_xlabel(\"Time (s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Z-score: mean={np.mean(X_zscore.value[0]):.3f}, std={np.std(X_zscore.value[0]):.3f}\")\n",
    "print(f\"Robust:  median={np.median(X_robust.value[0]):.3f}, MAD*1.4826={np.median(np.abs(X_robust.value[0] - np.median(X_robust.value[0]))) * 1.4826:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `MLPreprocessor` provides:\n",
    "\n",
    "1. **Flexible preprocessing** for any ML model (not just DeepClean)\n",
    "2. **DeepClean v2 compatibility** with identical processing order\n",
    "3. **Easy integration** with PyTorch, scikit-learn, XGBoost, etc.\n",
    "4. **Robust handling** of edge cases (single channel, outliers, zero variance)\n",
    "\n",
    "**Key processing order**:\n",
    "- Witness channels (X): Standardization only (no filtering)\n",
    "- Target channel (y): Filtering â†’ Standardization\n",
    "\n",
    "For more details, see the [API documentation](../../reference/api/preprocessing.rst)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
