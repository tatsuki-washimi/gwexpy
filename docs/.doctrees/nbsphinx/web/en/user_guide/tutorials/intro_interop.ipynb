{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWExPy TimeSeries Interoperability Tutorial\n",
    "\n",
    "This notebook introduces the new interoperability features added to the `gwexpy` `TimeSeries` class.\n",
    "`gwexpy` can seamlessly convert data to and from popular data science libraries such as Pandas, Xarray, PyTorch, and Astropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- 1. General Data Formats & Data Infrastructure\n",
    "    - 1.1. NumPy [Original GWpy]\n",
    "    - 1.2. Pandas Integration [Original GWpy]\n",
    "    - 1.3. Polars [GWExPy New]\n",
    "    - 1.4. Xarray Integration [Original GWpy]\n",
    "    - 1.5. Dask Integration [GWExPy New]\n",
    "    - 1.6. JSON / Python Dict (to_json) [GWExPy New]\n",
    "- 2. Database & Storage Layer\n",
    "    - 2.1. HDF5 [Original GWpy]\n",
    "    - 2.2. SQLite [GWExPy New]\n",
    "    - 2.3. Zarr [GWExPy New]\n",
    "    - 2.4. netCDF4 [GWExPy New]\n",
    "- 3. Computer Science, Machine Learning & Accelerated Computing\n",
    "    - 3.1. PyTorch Integration [GWExPy New]\n",
    "    - 3.2. CuPy (CUDA Acceleration) [GWExPy New]\n",
    "    - 3.3. TensorFlow Integration [GWExPy New]\n",
    "    - 3.4. JAX Integration [GWExPy New]\n",
    "- 4. Astronomy & Gravitational Wave Physics\n",
    "    - 4.1. PyCBC / LAL [Original GWpy]\n",
    "    - 4.2. Astropy Integration [Original GWpy]\n",
    "    - 4.3. Specutils Integration [GWExPy New]\n",
    "    - 4.4. Pyspeckit Integration [GWExPy New]\n",
    "- 5. Particle Physics & High Energy Physics\n",
    "    - 5.1. CERN ROOT Integration [GWExPy New]\n",
    "    - 5.2. Recovering from ROOT Objects (`from_root`)\n",
    "- 6. Geophysics, Seismology & Electromagnetics\n",
    "    - 6.1. ObsPy [Original GWpy]\n",
    "    - 6.2. SimPEG Integration [GWExPy New]\n",
    "    - 6.3. MTH5 / MTpy [GWExPy New]\n",
    "- 7. Acoustics & Audio Analysis\n",
    "    - 7.1. Librosa / Pydub [GWExPy New]\n",
    "- 8. Medical & Biosignal Analysis\n",
    "    - 8.1. MNE-Python [GWExPy New]\n",
    "    - 8.2. Elephant / quantities Integration [GWExPy New]\n",
    "    - 8.3. Neo [GWExPy New]\n",
    "- 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:21.864683Z",
     "iopub.status.busy": "2026-02-14T04:24:21.864538Z",
     "iopub.status.idle": "2026-02-14T04:24:21.872607Z",
     "shell.execute_reply": "2026-02-14T04:24:21.871786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:21.873865Z",
     "iopub.status.busy": "2026-02-14T04:24:21.873732Z",
     "iopub.status.idle": "2026-02-14T04:24:23.495145Z",
     "shell.execute_reply": "2026-02-14T04:24:23.494456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/miniconda3/envs/docs/lib/python3.11/site-packages/gwpy/time/_ligotimegps.py:42: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  from lal import LIGOTimeGPS\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gwpy.io.registry' has no attribute 'register_reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mastropy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m units \u001b[38;5;28;01mas\u001b[39;00m u\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgwpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LIGOTimeGPS\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgwexpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeries\n\u001b[32m     10\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWswiglal-redir-stdio\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, category=\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/docs/lib/python3.11/site-packages/gwexpy/__init__.py:49\u001b[39m\n\u001b[32m     44\u001b[39m warnings.filterwarnings(\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, message=\u001b[33m\"\u001b[39m\u001b[33mProtobuf gencode version\u001b[39m\u001b[33m\"\u001b[39m, category=\u001b[38;5;167;01mUserWarning\u001b[39;00m\n\u001b[32m     46\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Subpackages are available via namespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     50\u001b[39m     astro,\n\u001b[32m     51\u001b[39m     detector,\n\u001b[32m     52\u001b[39m     frequencyseries,\n\u001b[32m     53\u001b[39m     interop,\n\u001b[32m     54\u001b[39m     io,\n\u001b[32m     55\u001b[39m     noise,\n\u001b[32m     56\u001b[39m     plot,\n\u001b[32m     57\u001b[39m     segments,\n\u001b[32m     58\u001b[39m     signal,\n\u001b[32m     59\u001b[39m     spectral,\n\u001b[32m     60\u001b[39m     spectrogram,\n\u001b[32m     61\u001b[39m     table,\n\u001b[32m     62\u001b[39m     time,\n\u001b[32m     63\u001b[39m     timeseries,\n\u001b[32m     64\u001b[39m     types,\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfields\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FieldDict, FieldList, ScalarField, TensorField, VectorField\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/docs/lib/python3.11/site-packages/gwexpy/timeseries/__init__.py:36\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Register I/O readers on import\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Dynamic import from gwpy (PEP 562)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgwpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_gwpy_timeseries\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io \u001b[38;5;28;01mas\u001b[39;00m _io  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(name):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/docs/lib/python3.11/site-packages/gwexpy/timeseries/io/__init__.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Readers are registered on import\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     ats,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     13\u001b[39m     dttxml,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     14\u001b[39m     gbd,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     15\u001b[39m     sdb,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     16\u001b[39m     seismic,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     17\u001b[39m     stubs,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     18\u001b[39m     tdms,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     19\u001b[39m     wav,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     20\u001b[39m     win,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/docs/lib/python3.11/site-packages/gwexpy/timeseries/io/ats.py:221\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# -- Registration\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fmt \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mats\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[43mio_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_reader\u001b[49m(\n\u001b[32m    222\u001b[39m         fmt, TimeSeriesDict, read_timeseriesdict_ats, force=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    223\u001b[39m     )\n\u001b[32m    224\u001b[39m     io_registry.register_reader(fmt, TimeSeries, read_timeseries_ats, force=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    225\u001b[39m     io_registry.register_reader(\n\u001b[32m    226\u001b[39m         fmt,\n\u001b[32m    227\u001b[39m         TimeSeriesMatrix,\n\u001b[32m    228\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m *a, **k: read_timeseriesdict_ats(*a, **k).to_matrix(),\n\u001b[32m    229\u001b[39m         force=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    230\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: module 'gwpy.io.registry' has no attribute 'register_reader'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from gwpy.time import LIGOTimeGPS\n",
    "\n",
    "from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.496874Z",
     "iopub.status.busy": "2026-02-14T04:24:23.496720Z",
     "iopub.status.idle": "2026-02-14T04:24:23.518475Z",
     "shell.execute_reply": "2026-02-14T04:24:23.517867Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TimeSeries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m times = np.arange(size) * dt.value\n\u001b[32m      9\u001b[39m data = np.sin(\u001b[32m2\u001b[39m * np.pi * \u001b[32m1.0\u001b[39m * times)  \u001b[38;5;66;03m# 1Hz sine wave\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m ts = \u001b[43mTimeSeries\u001b[49m(data, t0=t0, dt=dt, unit=\u001b[33m\"\u001b[39m\u001b[33mV\u001b[39m\u001b[33m\"\u001b[39m, name=\u001b[33m\"\u001b[39m\u001b[33mdemo_signal\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal TimeSeries:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(ts)\n",
      "\u001b[31mNameError\u001b[39m: name 'TimeSeries' is not defined"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "# Generate a 10-second, 100Hz sine wave\n",
    "rate = 100 * u.Hz\n",
    "dt = 1 / rate\n",
    "t0 = LIGOTimeGPS(1234567890, 0)\n",
    "duration = 10 * u.s\n",
    "size = int(rate * duration)\n",
    "times = np.arange(size) * dt.value\n",
    "data = np.sin(2 * np.pi * 1.0 * times)  # 1Hz sine wave\n",
    "\n",
    "ts = TimeSeries(data, t0=t0, dt=dt, unit=\"V\", name=\"demo_signal\")\n",
    "print(\"Original TimeSeries:\")\n",
    "print(ts)\n",
    "ts.plot(title=\"Original TimeSeries\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General Data Formats & Data Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. NumPy <span style=\"color: #3498db; font-weight: bold;\">[Original GWpy]</span>\n",
    "\n",
    "> **NumPy**: NumPy is the foundational library for numerical computing in Python, providing multidimensional arrays and fast mathematical operations.\n",
    "> ðŸ“š [NumPy Documentation](https://numpy.org/)\n",
    "\n",
    "You can obtain NumPy arrays via `TimeSeries.value` or `np.asarray(ts)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Pandas Integration <span style=\"color: #3498db; font-weight: bold;\">[Original GWpy]</span>\n",
    "\n",
    "> **Pandas**: Pandas is a powerful library for data analysis and manipulation, providing flexible data structures through DataFrame and Series.\n",
    "> ðŸ“š [Pandas Documentation](https://pandas.pydata.org/)\n",
    "\n",
    "Using the `to_pandas()` method, you can convert `TimeSeries` to `pandas.Series`.\n",
    "The index can be selected from `datetime` (UTC), `gps`, or `seconds` (Unix timestamp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.520157Z",
     "iopub.status.busy": "2026-02-14T04:24:23.520014Z",
     "iopub.status.idle": "2026-02-14T04:24:23.539159Z",
     "shell.execute_reply": "2026-02-14T04:24:23.538396Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Convert to Pandas Series (default is datetime index)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     s_pd = \u001b[43mts\u001b[49m.to_pandas(index=\u001b[33m\"\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Converted to Pandas Series ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     display(s_pd)\n",
      "\u001b[31mNameError\u001b[39m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Convert to Pandas Series (default is datetime index)\n",
    "    s_pd = ts.to_pandas(index=\"datetime\")\n",
    "    print(\"\\n--- Converted to Pandas Series ---\")\n",
    "    display(s_pd)\n",
    "    s_pd.plot(title=\"Pandas Series\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Restore TimeSeries from Pandas Series\n",
    "    ts_restored = TimeSeries.from_pandas(s_pd, unit=\"V\")\n",
    "    print(\"\\n--- Restored TimeSeries from Pandas ---\")\n",
    "    print(ts_restored)\n",
    "\n",
    "    del s_pd, ts_restored\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Pandas is not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Polars <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **Polars**: Polars is a high-performance DataFrame library implemented in Rust, excelling at large-scale data processing.\n",
    "> ðŸ“š [Polars Documentation](https://pola.rs/)\n",
    "\n",
    "You can convert to Polars DataFrame/Series with `to_polars()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.540464Z",
     "iopub.status.busy": "2026-02-14T04:24:23.540319Z",
     "iopub.status.idle": "2026-02-14T04:24:23.544301Z",
     "shell.execute_reply": "2026-02-14T04:24:23.543671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import polars as pl\n",
    "\n",
    "    _ = pl\n",
    "    # TimeSeries -> Polars DataFrame\n",
    "    df_pl = ts.to_polars()\n",
    "    print(\"--- Polars DataFrame ---\")\n",
    "    print(df_pl.head())\n",
    "\n",
    "    # Plot using Polars/Matplotlib\n",
    "    plt.figure()\n",
    "    data_col = [c for c in df_pl.columns if c != \"time\"][0]\n",
    "    plt.plot(df_pl[\"time\"], df_pl[data_col])\n",
    "    plt.title(\"Polars Data Plot\")\n",
    "    plt.show()\n",
    "\n",
    "    # Recover to TimeSeries\n",
    "    from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "    ts_recovered = TimeSeries.from_polars(df_pl)\n",
    "    print(\"Recovered from Polars:\", ts_recovered)\n",
    "\n",
    "    del df_pl, ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Polars not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Xarray Integration <span style=\"color: #3498db; font-weight: bold;\">[Original GWpy]</span>\n",
    "\n",
    "> **xarray**: xarray is a library for multidimensional labeled arrays, widely used for manipulating NetCDF data and analyzing meteorological and earth science data.\n",
    "> ðŸ“š [xarray Documentation](https://docs.xarray.dev/)\n",
    "\n",
    "`xarray` is a powerful library for handling multidimensional labeled arrays. You can convert with `to_xarray()` while preserving metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.545629Z",
     "iopub.status.busy": "2026-02-14T04:24:23.545465Z",
     "iopub.status.idle": "2026-02-14T04:24:23.565085Z",
     "shell.execute_reply": "2026-02-14T04:24:23.564430Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Convert to Xarray DataArray\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     da = \u001b[43mts\u001b[49m.to_xarray()\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Converted to Xarray DataArray ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(da)\n",
      "\u001b[31mNameError\u001b[39m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Convert to Xarray DataArray\n",
    "    da = ts.to_xarray()\n",
    "    print(\"\\n--- Converted to Xarray DataArray ---\")\n",
    "    print(da)\n",
    "    # Verify metadata (attrs) is preserved\n",
    "    print(\"Attributes:\", da.attrs)\n",
    "\n",
    "    da.plot()\n",
    "    plt.title(\"Xarray DataArray\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Restore\n",
    "    ts_x = TimeSeries.from_xarray(da)\n",
    "    print(\"\\n--- Restored TimeSeries from Xarray ---\")\n",
    "    print(ts_x)\n",
    "\n",
    "    del da, ts_x\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Xarray is not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Dask Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **Dask**: Dask is a library for parallel computing that enables processing of large-scale data beyond NumPy/Pandas.\n",
    "> ðŸ“š [Dask Documentation](https://www.dask.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.566403Z",
     "iopub.status.busy": "2026-02-14T04:24:23.566260Z",
     "iopub.status.idle": "2026-02-14T04:24:23.569704Z",
     "shell.execute_reply": "2026-02-14T04:24:23.569105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dask.array as da\n",
    "\n",
    "    _ = da\n",
    "    # Convert to Dask Array\n",
    "    dask_arr = ts.to_dask(chunks=\"auto\")\n",
    "    print(\"\\n--- Converted to Dask Array ---\")\n",
    "    print(dask_arr)\n",
    "\n",
    "    # Restore (compute=True loads immediately)\n",
    "    ts_from_dask = TimeSeries.from_dask(dask_arr, t0=ts.t0, dt=ts.dt, unit=ts.unit)\n",
    "    print(\"Recovered from Dask:\", ts_from_dask)\n",
    "\n",
    "    del dask_arr, ts_from_dask\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Dask not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. JSON / Python Dict (to_json) <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **JSON**: JSON (JavaScript Object Notation) is a lightweight data exchange format supported by the Python standard library.\n",
    "> ðŸ“š [JSON Documentation](https://docs.python.org/3/library/json.html)\n",
    "\n",
    "You can output JSON-compatible dictionary format with `to_json()` or `to_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.570954Z",
     "iopub.status.busy": "2026-02-14T04:24:23.570826Z",
     "iopub.status.idle": "2026-02-14T04:24:23.590681Z",
     "shell.execute_reply": "2026-02-14T04:24:23.590030Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# TimeSeries -> JSON string\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ts_json = \u001b[43mts\u001b[49m.to_json()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- JSON Representation (Partial) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(ts_json[:\u001b[32m500\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# TimeSeries -> JSON string\n",
    "ts_json = ts.to_json()\n",
    "print(\"--- JSON Representation (Partial) ---\")\n",
    "print(ts_json[:500] + \"...\")\n",
    "\n",
    "# Plot data by loading back from JSON\n",
    "ts_dict_temp = json.loads(ts_json)\n",
    "plt.figure()\n",
    "plt.plot(ts_dict_temp[\"data\"])\n",
    "plt.title(\"Plot from JSON Data\")\n",
    "plt.show()\n",
    "\n",
    "# Recover from JSON\n",
    "from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "ts_recovered = TimeSeries.from_json(ts_json)\n",
    "print(\"Recovered from JSON:\", ts_recovered)\n",
    "\n",
    "del ts_json, ts_dict_temp, ts_recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database & Storage Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. HDF5 <span style=\"color: #3498db; font-weight: bold;\">[Original GWpy]</span>\n",
    "\n",
    "> **HDF5**: HDF5 is a hierarchical data format for efficiently storing and managing large-scale scientific data. It can be accessed from Python via the h5py library.\n",
    "> ðŸ“š [HDF5 Documentation](https://www.h5py.org/)\n",
    "\n",
    "Supports saving to HDF5 with `to_hdf5_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.592067Z",
     "iopub.status.busy": "2026-02-14T04:24:23.591936Z",
     "iopub.status.idle": "2026-02-14T04:24:23.614901Z",
     "shell.execute_reply": "2026-02-14T04:24:23.614194Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tempfile.NamedTemporaryFile(suffix=\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tmp:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# TimeSeries -> HDF5\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m h5py.File(tmp.name, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         \u001b[43mts\u001b[49m.to_hdf5_dataset(f, \u001b[33m\"\u001b[39m\u001b[33mdataset_01\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Read back and display\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m h5py.File(tmp.name, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tempfile\n",
    "\n",
    "    import h5py\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".h5\") as tmp:\n",
    "        # TimeSeries -> HDF5\n",
    "        with h5py.File(tmp.name, \"w\") as f:\n",
    "            ts.to_hdf5_dataset(f, \"dataset_01\")\n",
    "\n",
    "        # Read back and display\n",
    "        with h5py.File(tmp.name, \"r\") as f:\n",
    "            ds = f[\"dataset_01\"]\n",
    "            print(\"--- HDF5 Dataset Info ---\")\n",
    "            print(f\"Shape: {ds.shape}, Dtype: {ds.dtype}\")\n",
    "            print(\"Attributes:\", dict(ds.attrs))\n",
    "\n",
    "            # Recover\n",
    "            from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "            ts_recovered = TimeSeries.from_hdf5_dataset(f, \"dataset_01\")\n",
    "            print(\"Recovered from HDF5:\", ts_recovered)\n",
    "\n",
    "            ts_recovered.plot()\n",
    "            plt.title(\"Recovered from HDF5\")\n",
    "            plt.show()\n",
    "\n",
    "            del ds, ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"h5py not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. SQLite <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **SQLite**: SQLite is a lightweight embedded SQL database engine included in the Python standard library.\n",
    "> ðŸ“š [SQLite Documentation](https://docs.python.org/3/library/sqlite3.html)\n",
    "\n",
    "Supports database persistence with `to_sqlite()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.616320Z",
     "iopub.status.busy": "2026-02-14T04:24:23.616192Z",
     "iopub.status.idle": "2026-02-14T04:24:23.636288Z",
     "shell.execute_reply": "2026-02-14T04:24:23.635631Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m conn = sqlite3.connect(\u001b[33m\"\u001b[39m\u001b[33m:memory:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# TimeSeries -> SQLite\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m series_id = \u001b[43mts\u001b[49m.to_sqlite(conn, series_id=\u001b[33m\"\u001b[39m\u001b[33mtest_series\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved to SQLite with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Verify data in SQL\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# TimeSeries -> SQLite\n",
    "series_id = ts.to_sqlite(conn, series_id=\"test_series\")\n",
    "print(f\"Saved to SQLite with ID: {series_id}\")\n",
    "\n",
    "# Verify data in SQL\n",
    "cursor = conn.cursor()\n",
    "row = cursor.execute(\"SELECT * FROM series WHERE series_id=?\", (series_id,)).fetchone()\n",
    "print(\"Metadata from SQL:\", row)\n",
    "\n",
    "# Recover\n",
    "from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "ts_recovered = TimeSeries.from_sqlite(conn, series_id)\n",
    "print(\"Recovered from SQLite:\", ts_recovered)\n",
    "\n",
    "ts_recovered.plot()\n",
    "plt.title(\"Recovered from SQLite\")\n",
    "plt.show()\n",
    "\n",
    "del series_id, conn, cursor, ts_recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Zarr <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **Zarr**: Zarr is a storage format for chunked, compressed multidimensional arrays with excellent cloud storage integration.\n",
    "> ðŸ“š [Zarr Documentation](https://zarr.dev/)\n",
    "\n",
    "Supports cloud storage-friendly formats with `to_zarr()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.637651Z",
     "iopub.status.busy": "2026-02-14T04:24:23.637458Z",
     "iopub.status.idle": "2026-02-14T04:24:23.641414Z",
     "shell.execute_reply": "2026-02-14T04:24:23.640850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarr not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import os\n",
    "    import tempfile\n",
    "\n",
    "    import zarr\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        store_path = os.path.join(tmpdir, \"test.zarr\")\n",
    "        # TimeSeries -> Zarr\n",
    "        ts.to_zarr(store_path, path=\"timeseries\")\n",
    "\n",
    "        # Read back\n",
    "        z = zarr.open(store_path, mode=\"r\")\n",
    "        ds = z[\"timeseries\"]\n",
    "        print(\"--- Zarr Array Info ---\")\n",
    "        print(ds.info)\n",
    "\n",
    "        # Recover\n",
    "        from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "        ts_recovered = TimeSeries.from_zarr(store_path, \"timeseries\")\n",
    "        print(\"Recovered from Zarr:\", ts_recovered)\n",
    "\n",
    "        ts_recovered.plot()\n",
    "        plt.title(\"Recovered from Zarr\")\n",
    "        plt.show()\n",
    "\n",
    "        del z, ds, ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"zarr not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. netCDF4 <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **netCDF4**: netCDF4 is a standard format for meteorological, oceanographic, and earth science data with self-describing data structures.\n",
    "> ðŸ“š [netCDF4 Documentation](https://unidata.github.io/netcdf4-python/)\n",
    "\n",
    "Supports meteorological and oceanographic data standards with `to_netcdf4()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.642687Z",
     "iopub.status.busy": "2026-02-14T04:24:23.642561Z",
     "iopub.status.idle": "2026-02-14T04:24:23.646634Z",
     "shell.execute_reply": "2026-02-14T04:24:23.645986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netCDF4 not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tempfile\n",
    "\n",
    "    import netCDF4\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".nc\") as tmp:\n",
    "        # TimeSeries -> netCDF4\n",
    "        with netCDF4.Dataset(tmp.name, \"w\") as ds:\n",
    "            ts.to_netcdf4(ds, \"my_signal\")\n",
    "\n",
    "        # Read back\n",
    "        with netCDF4.Dataset(tmp.name, \"r\") as ds:\n",
    "            v = ds.variables[\"my_signal\"]\n",
    "            print(\"--- netCDF4 Variable Info ---\")\n",
    "            print(v)\n",
    "\n",
    "            # Recover\n",
    "            from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "            ts_recovered = TimeSeries.from_netcdf4(ds, \"my_signal\")\n",
    "            print(\"Recovered from netCDF4:\", ts_recovered)\n",
    "\n",
    "            ts_recovered.plot()\n",
    "            plt.title(\"Recovered from netCDF4\")\n",
    "            plt.show()\n",
    "\n",
    "            del v, ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"netCDF4 not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computer Science, Machine Learning & Accelerated Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. PyTorch Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **PyTorch**: PyTorch is a deep learning framework supporting dynamic computation graphs and GPU acceleration.\n",
    "> ðŸ“š [PyTorch Documentation](https://pytorch.org/)\n",
    "\n",
    "For deep learning preprocessing, you can directly convert `TimeSeries` to `torch.Tensor`. GPU transfer is also supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.647959Z",
     "iopub.status.busy": "2026-02-14T04:24:23.647831Z",
     "iopub.status.idle": "2026-02-14T04:24:23.651346Z",
     "shell.execute_reply": "2026-02-14T04:24:23.650827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not installed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"3\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    # Convert to PyTorch Tensor\n",
    "    tensor = ts.to_torch(dtype=torch.float32)\n",
    "    print(\"\\n--- Converted to PyTorch Tensor ---\")\n",
    "    print(f\"Tensor shape: {tensor.shape}, dtype: {tensor.dtype}\")\n",
    "\n",
    "    # Restore from Tensor (t0, dt must be specified separately)\n",
    "    ts_torch = TimeSeries.from_torch(tensor, t0=ts.t0, dt=ts.dt, unit=\"V\")\n",
    "    print(\"\\n--- Restored from Torch ---\")\n",
    "    print(ts_torch)\n",
    "\n",
    "    del tensor, ts_torch\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. CuPy (CUDA Acceleration) <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **CuPy**: CuPy is a NumPy-compatible GPU array library that enables high-speed computation using NVIDIA CUDA.\n",
    "> ðŸ“š [CuPy Documentation](https://cupy.dev/)\n",
    "\n",
    "You can convert to CuPy arrays for GPU-based computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.652819Z",
     "iopub.status.busy": "2026-02-14T04:24:23.652688Z",
     "iopub.status.idle": "2026-02-14T04:24:23.656517Z",
     "shell.execute_reply": "2026-02-14T04:24:23.655902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy or CUDA driver not available.\n"
     ]
    }
   ],
   "source": [
    "from gwexpy.interop import is_cupy_available\n",
    "\n",
    "if is_cupy_available():\n",
    "    import cupy as cp\n",
    "\n",
    "    # TimeSeries -> CuPy\n",
    "    y_gpu = ts.to_cupy()\n",
    "    print(\"--- CuPy Array (on GPU) ---\")\n",
    "    print(y_gpu)\n",
    "\n",
    "    # Simple processing on GPU\n",
    "    y_gpu_filt = y_gpu * 2.0\n",
    "\n",
    "    # Plot (must move to CPU for plotting)\n",
    "    plt.figure()\n",
    "    plt.plot(cp.asnumpy(y_gpu_filt))\n",
    "    plt.title(\"CuPy Data (Moved to CPU for plot)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Recover\n",
    "    from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "    ts_recovered = TimeSeries.from_cupy(y_gpu_filt, t0=ts.t0, dt=ts.dt)\n",
    "    print(\"Recovered from CuPy:\", ts_recovered)\n",
    "\n",
    "    del y_gpu, y_gpu_filt, ts_recovered\n",
    "\n",
    "else:\n",
    "    print(\"CuPy or CUDA driver not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. TensorFlow Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **TensorFlow**: TensorFlow is a machine learning platform developed by Google, excelling at large-scale production environments.\n",
    "> ðŸ“š [TensorFlow Documentation](https://www.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.657738Z",
     "iopub.status.busy": "2026-02-14T04:24:23.657601Z",
     "iopub.status.idle": "2026-02-14T04:24:23.662569Z",
     "shell.execute_reply": "2026-02-14T04:24:23.661315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import os\n",
    "    import warnings\n",
    "\n",
    "    os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"3\")\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\", category=UserWarning, module=r\"google\\.protobuf\\..*\"\n",
    "    )\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\", category=UserWarning, message=r\"Protobuf gencode version.*\"\n",
    "    )\n",
    "    import tensorflow as tf\n",
    "\n",
    "    _ = tf\n",
    "    # Convert to TensorFlow Tensor\n",
    "    tf_tensor = ts.to_tensorflow()\n",
    "    print(\"\\n--- Converted to TensorFlow Tensor ---\")\n",
    "    print(f\"Tensor shape: {tf_tensor.shape}\")\n",
    "    print(f\"Tensor dtype: {tf_tensor.dtype}\")\n",
    "\n",
    "    # Restore\n",
    "    ts_from_tensorflow = TimeSeries.from_tensorflow(\n",
    "        tf_tensor, t0=ts.t0, dt=ts.dt, unit=ts.unit\n",
    "    )\n",
    "    print(\"Recovered from TF:\", ts_from_tensorflow)\n",
    "\n",
    "    del tf_tensor, ts_from_tensorflow\n",
    "\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. JAX Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **JAX**: JAX is a high-performance numerical computing library developed by Google, featuring automatic differentiation and XLA compilation for acceleration.\n",
    "> ðŸ“š [JAX Documentation](https://jax.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.663814Z",
     "iopub.status.busy": "2026-02-14T04:24:23.663691Z",
     "iopub.status.idle": "2026-02-14T04:24:23.667194Z",
     "shell.execute_reply": "2026-02-14T04:24:23.666597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import os\n",
    "\n",
    "    os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "    import jax\n",
    "\n",
    "    _ = jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    _ = jnp\n",
    "    # Convert to JAX Array\n",
    "    jax_arr = ts.to_jax()\n",
    "    print(\"\\n--- Converted to JAX Array ---\")\n",
    "    print(f\"Array shape: {jax_arr.shape}\")\n",
    "\n",
    "    # Restore\n",
    "    ts_from_jax = TimeSeries.from_jax(jax_arr, t0=ts.t0, dt=ts.dt, unit=ts.unit)\n",
    "    print(\"Recovered from JAX:\", ts_from_jax)\n",
    "\n",
    "    del jax_arr, ts_from_jax\n",
    "except ImportError:\n",
    "    print(\"JAX not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Astronomy & Gravitational Wave Physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. PyCBC / LAL <span style=\"color: #3498db; font-weight: bold;\">[Original GWpy]</span>\n",
    "\n",
    "> **LAL**: LAL (LIGO Algorithm Library) is the official analysis library for LIGO/Virgo, providing the foundation for gravitational wave analysis.\n",
    "> ðŸ“š [LAL Documentation](https://lscsoft.docs.ligo.org/lalsuite/)\n",
    "\n",
    "> **PyCBC**: PyCBC is a library for gravitational wave data analysis, used for signal searches and parameter estimation.\n",
    "> ðŸ“š [PyCBC Documentation](https://pycbc.org/)\n",
    "\n",
    "Provides compatibility with standard gravitational wave analysis tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Astropy Integration <span style=\"color: #3498db; font-weight: bold;\">[Original GWpy]</span>\n",
    "\n",
    "> **Astropy**: Astropy is a Python library for astronomy, supporting coordinate transformations, time system conversions, unit systems, and more.\n",
    "> ðŸ“š [Astropy Documentation](https://www.astropy.org/)\n",
    "\n",
    "Also supports interconversion with `astropy.timeseries.TimeSeries`, which is standard in the astronomy field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.668495Z",
     "iopub.status.busy": "2026-02-14T04:24:23.668364Z",
     "iopub.status.idle": "2026-02-14T04:24:23.688984Z",
     "shell.execute_reply": "2026-02-14T04:24:23.688388Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Convert to Astropy TimeSeries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     ap_ts = \u001b[43mts\u001b[49m.to_astropy_timeseries()\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Converted to Astropy TimeSeries ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(ap_ts[:\u001b[32m5\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Convert to Astropy TimeSeries\n",
    "    ap_ts = ts.to_astropy_timeseries()\n",
    "    print(\"\\n--- Converted to Astropy TimeSeries ---\")\n",
    "    print(ap_ts[:5])\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(ap_ts.time.jd, ap_ts[\"value\"])\n",
    "    plt.title(\"Astropy TimeSeries\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Restore\n",
    "    ts_astro = TimeSeries.from_astropy_timeseries(ap_ts)\n",
    "    print(\"\\n--- Restored from Astropy ---\")\n",
    "    print(ts_astro)\n",
    "\n",
    "    del ap_ts, ts_astro\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Astropy is not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Specutils Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **specutils**: specutils is an Astropy-affiliated package for manipulating and analyzing astronomical spectral data.\n",
    "> ðŸ“š [specutils Documentation](https://specutils.readthedocs.io/)\n",
    "\n",
    "`FrequencySeries` can interconvert with `Spectrum1D` objects from the Astropy ecosystem spectral analysis library `specutils`.\n",
    "Units and frequency axes are properly preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.690342Z",
     "iopub.status.busy": "2026-02-14T04:24:23.690214Z",
     "iopub.status.idle": "2026-02-14T04:24:23.693696Z",
     "shell.execute_reply": "2026-02-14T04:24:23.693063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specutils library not found. Skipping example.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import specutils\n",
    "\n",
    "    _ = specutils\n",
    "\n",
    "    from gwexpy.frequencyseries import FrequencySeries\n",
    "\n",
    "    # FrequencySeries -> specutils.Spectrum1D\n",
    "    fs = FrequencySeries(\n",
    "        np.random.random(100), frequencies=np.linspace(10, 100, 100), unit=\"Jy\"\n",
    "    )\n",
    "    spec = fs.to_specutils()\n",
    "    print(\"specutils Spectrum1D:\", spec)\n",
    "    print(\"Spectral axis unit:\", spec.spectral_axis.unit)\n",
    "\n",
    "    # specutils.Spectrum1D -> FrequencySeries\n",
    "    fs_rec = FrequencySeries.from_specutils(spec)\n",
    "    print(\"Restored FrequencySeries unit:\", fs_rec.unit)\n",
    "\n",
    "    del fs, spec, fs_rec\n",
    "\n",
    "except ImportError:\n",
    "    print(\"specutils library not found. Skipping example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Pyspeckit Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **PySpecKit**: PySpecKit is a spectral analysis toolkit for radio astronomy, supporting spectral line fitting and more.\n",
    "> ðŸ“š [PySpecKit Documentation](https://pyspeckit.readthedocs.io/)\n",
    "\n",
    "`FrequencySeries` can also integrate with `Spectrum` objects from the general-purpose spectral analysis toolkit `pyspeckit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.694950Z",
     "iopub.status.busy": "2026-02-14T04:24:23.694830Z",
     "iopub.status.idle": "2026-02-14T04:24:23.698453Z",
     "shell.execute_reply": "2026-02-14T04:24:23.697847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspeckit library not found. Skipping example.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pyspeckit\n",
    "\n",
    "    _ = pyspeckit\n",
    "    from gwexpy.frequencyseries import FrequencySeries\n",
    "\n",
    "    # FrequencySeries -> pyspeckit.Spectrum\n",
    "    fs = FrequencySeries(np.random.random(100), frequencies=np.linspace(10, 100, 100))\n",
    "    spec = fs.to_pyspeckit()\n",
    "    print(\"pyspeckit Spectrum length:\", len(spec.data))\n",
    "\n",
    "    # pyspeckit.Spectrum -> FrequencySeries\n",
    "    fs_rec = FrequencySeries.from_pyspeckit(spec)\n",
    "    print(\"Restored FrequencySeries length:\", len(fs_rec))\n",
    "\n",
    "    del fs, spec, fs_rec\n",
    "\n",
    "except ImportError:\n",
    "    print(\"pyspeckit library not found. Skipping example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Particle Physics & High Energy Physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. CERN ROOT Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **ROOT**: ROOT is a data analysis framework for high-energy physics developed by CERN.\n",
    "> ðŸ“š [ROOT Documentation](https://root.cern/)\n",
    "\n",
    "Enhanced interoperability with **ROOT**, the standard tool in high-energy physics.\n",
    "`gwexpy` Series objects can be quickly converted to ROOT's `TGraph`, `TH1D`, or `TH2D`, and you can create ROOT files.\n",
    "Conversely, you can also restore `TimeSeries` and other objects from ROOT objects.\n",
    "\n",
    "**Note**: Using this feature requires `ROOT` (PyROOT) to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.699749Z",
     "iopub.status.busy": "2026-02-14T04:24:23.699630Z",
     "iopub.status.idle": "2026-02-14T04:24:23.704116Z",
     "shell.execute_reply": "2026-02-14T04:24:23.703535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT is not installed. Skipping ROOT examples.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    import ROOT\n",
    "\n",
    "    from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "    # Prepare data\n",
    "    t = np.linspace(0, 10, 1000)\n",
    "    data = np.sin(2 * np.pi * 1.0 * t) + np.random.normal(0, 0.5, size=len(t))\n",
    "    ts = TimeSeries(data, dt=t[1] - t[0], name=\"signal\")\n",
    "\n",
    "    # --- 1. Convert to TGraph ---\n",
    "    # Vectorized high-speed conversion\n",
    "    graph = ts.to_tgraph()\n",
    "\n",
    "    # Plot on ROOT canvas\n",
    "    c1 = ROOT.TCanvas(\"c1\", \"TGraph Example\", 800, 600)\n",
    "    graph.SetTitle(\"ROOT TGraph;GPS Time [s];Amplitude\")\n",
    "    graph.Draw(\"AL\")\n",
    "    c1.Draw()\n",
    "    # c1.SaveAs(\"signal_graph.png\") # To save as an image\n",
    "\n",
    "    print(f\"Created TGraph: {graph.GetName()} with {graph.GetN()} points\")\n",
    "\n",
    "    # --- 2. Convert to TH1D (Histogram) ---\n",
    "    # Convert as histogram (binning is automatic or can be specified)\n",
    "    hist = ts.to_th1d()\n",
    "\n",
    "    c2 = ROOT.TCanvas(\"c2\", \"TH1D Example\", 800, 600)\n",
    "    hist.SetTitle(\"ROOT TH1D;GPS Time [s];Amplitude\")\n",
    "    hist.SetLineColor(ROOT.kRed)\n",
    "    hist.Draw()\n",
    "    c2.Draw()\n",
    "\n",
    "    print(f\"Created TH1D: {hist.GetName()} with {hist.GetNbinsX()} bins\")\n",
    "\n",
    "    del t, data, graph, hist, c1, c2\n",
    "\n",
    "except ImportError:\n",
    "    print(\"ROOT is not installed. Skipping ROOT examples.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Recovering from ROOT Objects (`from_root`)\n",
    "\n",
    "> **ROOT**: ROOT is a data analysis framework for high-energy physics developed by CERN.\n",
    "> ðŸ“š [ROOT Documentation](https://root.cern/)\n",
    "\n",
    "You can load histograms and graphs from existing ROOT files and convert them back to `gwexpy` objects for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.705368Z",
     "iopub.status.busy": "2026-02-14T04:24:23.705245Z",
     "iopub.status.idle": "2026-02-14T04:24:23.708318Z",
     "shell.execute_reply": "2026-02-14T04:24:23.707626Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if \"hist\" in locals() and hist:\n",
    "        # ROOT TH1D -> TimeSeries\n",
    "        # Reads histogram bin contents as time series data\n",
    "        ts_restored = from_root(TimeSeries, hist)\n",
    "\n",
    "        print(f\"Restored TimeSeries: {ts_restored.name}\")\n",
    "        print(ts_restored)\n",
    "\n",
    "        # Restore from TGraph similarly\n",
    "        ts_from_graph = from_root(TimeSeries, graph)\n",
    "        print(f\"Restored from TGraph: {len(ts_from_graph)} samples\")\n",
    "\n",
    "        del ts_restored, ts_from_graph\n",
    "\n",
    "except NameError:\n",
    "    pass  # If hist or graph were not created\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geophysics, Seismology & Electromagnetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. ObsPy <span style=\"color: #3498db; font-weight: bold;\">[Original GWpy]</span>\n",
    "\n",
    "> **ObsPy**: ObsPy is a Python library for acquiring, processing, and analyzing seismological data, supporting formats like MiniSEED.\n",
    "> ðŸ“š [ObsPy Documentation](https://docs.obspy.org/)\n",
    "\n",
    "Supports interoperability with ObsPy, which is standard in seismology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.709500Z",
     "iopub.status.busy": "2026-02-14T04:24:23.709378Z",
     "iopub.status.idle": "2026-02-14T04:24:23.712826Z",
     "shell.execute_reply": "2026-02-14T04:24:23.712133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObsPy not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import obspy\n",
    "\n",
    "    _ = obspy\n",
    "    # TimeSeries -> ObsPy Trace\n",
    "    tr = ts.to_obspy()\n",
    "    print(\"--- ObsPy Trace ---\")\n",
    "    print(tr)\n",
    "\n",
    "    # Plot using ObsPy\n",
    "    tr.plot()\n",
    "\n",
    "    # Recover to TimeSeries\n",
    "    from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "    ts_recovered = TimeSeries.from_obspy(tr)\n",
    "    print(\"Recovered from ObsPy:\", ts_recovered)\n",
    "\n",
    "    del tr, ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"ObsPy not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.714098Z",
     "iopub.status.busy": "2026-02-14T04:24:23.713959Z",
     "iopub.status.idle": "2026-02-14T04:24:23.716954Z",
     "shell.execute_reply": "2026-02-14T04:24:23.716350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObsPy not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import obspy\n",
    "\n",
    "    _ = obspy\n",
    "    tr = ts.to_obspy()\n",
    "    print(\"ObsPy Trace:\", tr)\n",
    "\n",
    "    del tr\n",
    "\n",
    "except ImportError:\n",
    "    print(\"ObsPy not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. SimPEG Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **SimPEG**: SimPEG is a simulation and estimation framework for geophysical inverse problems.\n",
    "> ðŸ“š [SimPEG Documentation](https://simpeg.xyz/)\n",
    "\n",
    "`gwexpy` supports integration with `SimPEG`, a forward modeling and inversion library for geophysics.\n",
    "`TimeSeries` (TDEM) and `FrequencySeries` (FDEM) can be converted to `simpeg.data.Data` objects and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.718263Z",
     "iopub.status.busy": "2026-02-14T04:24:23.718125Z",
     "iopub.status.idle": "2026-02-14T04:24:23.722243Z",
     "shell.execute_reply": "2026-02-14T04:24:23.721630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimPEG library not found. Skipping example.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    import simpeg\n",
    "\n",
    "    _ = simpeg\n",
    "    from simpeg import maps\n",
    "\n",
    "    _ = maps\n",
    "\n",
    "    from gwexpy.frequencyseries import FrequencySeries\n",
    "    from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "    # --- TimeSeries -> SimPEG (TDEM assumption) ---\n",
    "    ts = TimeSeries(np.random.normal(size=100), dt=0.01, unit=\"A/m^2\")\n",
    "    simpeg_data_td = ts.to_simpeg(location=np.array([0, 0, 0]))\n",
    "    print(\"SimPEG TDEM data shape:\", simpeg_data_td.dobs.shape)\n",
    "\n",
    "    # --- FrequencySeries -> SimPEG (FDEM assumption) ---\n",
    "    fs = FrequencySeries(\n",
    "        np.random.normal(size=10) + 1j * 0.1, frequencies=np.logspace(0, 3, 10)\n",
    "    )\n",
    "    simpeg_data_fd = fs.to_simpeg(location=np.array([0, 0, 0]), orientation=\"z\")\n",
    "    print(\"SimPEG FDEM data shape:\", simpeg_data_fd.dobs.shape)\n",
    "\n",
    "    del simpeg_data_td, simpeg_data_fd, fs\n",
    "\n",
    "except ImportError:\n",
    "    print(\"SimPEG library not found. Skipping example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. MTH5 / MTpy <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **MTH5**: MTH5 is an HDF5-based data format for magnetotelluric (MT) data.\n",
    "> ðŸ“š [MTH5 Documentation](https://mth5.readthedocs.io/)\n",
    "\n",
    "Supports MTH5 storage for magnetotelluric method data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.723416Z",
     "iopub.status.busy": "2026-02-14T04:24:23.723283Z",
     "iopub.status.idle": "2026-02-14T04:24:23.727314Z",
     "shell.execute_reply": "2026-02-14T04:24:23.726781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mth5 not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import logging\n",
    "    import tempfile\n",
    "\n",
    "    logging.getLogger(\"mth5\").setLevel(logging.ERROR)\n",
    "    logging.getLogger(\"mt_metadata\").setLevel(logging.ERROR)\n",
    "\n",
    "    import mth5\n",
    "\n",
    "    _ = mth5\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".h5\") as tmp:\n",
    "        from gwexpy.interop.mt_ import from_mth5, to_mth5\n",
    "\n",
    "        # TimeSeries -> MTH5\n",
    "        # We need to provide station and run names for MTH5 structure\n",
    "        to_mth5(ts, tmp.name, station=\"SITE01\", run=\"RUN01\")\n",
    "        print(f\"Saved to MTH5 file: {tmp.name}\")\n",
    "\n",
    "        # Display structure info if needed, or just recover\n",
    "        # Recover\n",
    "        ts_recovered = from_mth5(tmp.name, \"SITE01\", \"RUN01\", ts.name or \"Ex\")\n",
    "        print(\"Recovered from MTH5:\", ts_recovered)\n",
    "\n",
    "        ts_recovered.plot()\n",
    "        plt.title(\"Recovered from MTH5\")\n",
    "        plt.show()\n",
    "\n",
    "        del ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"mth5 not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Acoustics & Audio Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Librosa / Pydub <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **pydub**: pydub is a simple library for audio file manipulation (editing, conversion, effects).\n",
    "> ðŸ“š [pydub Documentation](https://github.com/jiaaro/pydub)\n",
    "\n",
    "> **librosa**: librosa is a library for audio and music analysis, providing features like spectral analysis and beat detection.\n",
    "> ðŸ“š [librosa Documentation](https://librosa.org/)\n",
    "\n",
    "Supports integration with audio processing libraries Librosa and Pydub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.728670Z",
     "iopub.status.busy": "2026-02-14T04:24:23.728553Z",
     "iopub.status.idle": "2026-02-14T04:24:23.732145Z",
     "shell.execute_reply": "2026-02-14T04:24:23.731595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librosa not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import librosa\n",
    "\n",
    "    _ = librosa\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # TimeSeries -> Librosa (y, sr)\n",
    "    y, sr = ts.to_librosa()\n",
    "    print(f\"--- Librosa Data ---\\nSignal shape: {y.shape}, Sample rate: {sr}\")\n",
    "\n",
    "    # Plot using librosa style (matplotlib)\n",
    "    plt.figure()\n",
    "    plt.plot(y[:1000])  # Plot first 1000 samples\n",
    "    plt.title(\"Librosa Audio Signal (Zoom)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Recover to TimeSeries\n",
    "    from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "    ts_recovered = TimeSeries(y, dt=1.0 / sr)\n",
    "    print(\"Recovered from Librosa:\", ts_recovered)\n",
    "\n",
    "    del y, sr\n",
    "except ImportError:\n",
    "    print(\"Librosa not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Medical & Biosignal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. MNE-Python <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **MNE**: MNE-Python is a library for analyzing EEG and MEG data, widely used in neuroscience research.\n",
    "> ðŸ“š [MNE Documentation](https://mne.tools/)\n",
    "\n",
    "Integration with MNE for electroencephalography (EEG/MEG) analysis packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.733457Z",
     "iopub.status.busy": "2026-02-14T04:24:23.733325Z",
     "iopub.status.idle": "2026-02-14T04:24:23.736645Z",
     "shell.execute_reply": "2026-02-14T04:24:23.735973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNE not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import mne\n",
    "\n",
    "    _ = mne\n",
    "    # TimeSeries -> MNE Raw\n",
    "    raw = ts.to_mne()\n",
    "    print(\"--- MNE Raw ---\")\n",
    "    print(raw)\n",
    "\n",
    "    # Display info\n",
    "    print(raw.info)\n",
    "\n",
    "    # Recover to TimeSeries\n",
    "    from gwexpy.timeseries import TimeSeries\n",
    "\n",
    "    ts_recovered = TimeSeries.from_mne(raw, channel=ts.name or \"ch0\")\n",
    "    print(\"Recovered from MNE:\", ts_recovered)\n",
    "\n",
    "    del raw, ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"MNE not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.737818Z",
     "iopub.status.busy": "2026-02-14T04:24:23.737678Z",
     "iopub.status.idle": "2026-02-14T04:24:23.740721Z",
     "shell.execute_reply": "2026-02-14T04:24:23.740023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNE not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import mne\n",
    "\n",
    "    _ = mne\n",
    "    raw = ts.to_mne()\n",
    "    print(\"MNE Raw:\", raw)\n",
    "\n",
    "    del raw\n",
    "except ImportError:\n",
    "    print(\"MNE not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Elephant / quantities Integration <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "`gwexpy`'s `FrequencySeries` and `Spectrogram` can interconvert with `quantities.Quantity` objects.\n",
    "This is useful for integration with Elephant and Neo.\n",
    "\n",
    "Note: Requires `pip install quantities` beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.741905Z",
     "iopub.status.busy": "2026-02-14T04:24:23.741780Z",
     "iopub.status.idle": "2026-02-14T04:24:23.745339Z",
     "shell.execute_reply": "2026-02-14T04:24:23.744731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantities library not found. Skipping example.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    import quantities as pq\n",
    "\n",
    "    _ = pq\n",
    "    from gwexpy.frequencyseries import FrequencySeries\n",
    "\n",
    "    # Create FrequencySeries\n",
    "    freqs = np.linspace(0, 100, 101)\n",
    "    data_fs = np.random.random(101)\n",
    "    fs = FrequencySeries(data_fs, frequencies=freqs, unit=\"V\")\n",
    "\n",
    "    # to_quantities\n",
    "    q_obj = fs.to_quantities(units=\"mV\")\n",
    "    print(\"Quantities object:\", q_obj)\n",
    "\n",
    "    # from_quantities\n",
    "    fs_new = FrequencySeries.from_quantities(q_obj, frequencies=freqs)\n",
    "    print(\"Restored FrequencySeries unit:\", fs_new.unit)\n",
    "\n",
    "    del freqs, data_fs, fs, q_obj, fs_new\n",
    "\n",
    "except ImportError:\n",
    "    print(\"quantities library not found. Skipping example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Neo <span style=\"color: #2ecc71; font-weight: bold;\">[GWExPy New]</span>\n",
    "\n",
    "> **Neo**: Neo is a data structure library for electrophysiology data (neuroscience), supporting input/output to various formats.\n",
    "> ðŸ“š [Neo Documentation](https://neo.readthedocs.io/)\n",
    "\n",
    "Supports conversion to Neo, a common standard for electrophysiological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:24:23.746644Z",
     "iopub.status.busy": "2026-02-14T04:24:23.746485Z",
     "iopub.status.idle": "2026-02-14T04:24:23.750678Z",
     "shell.execute_reply": "2026-02-14T04:24:23.750002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neo not installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import neo\n",
    "\n",
    "    _ = neo\n",
    "    # TimeSeries -> Neo AnalogSignal\n",
    "    # to_neo is available in gwexpy.interop\n",
    "    # Note: TimeseriesMatrix is preferred for multi-channel Neo conversion,\n",
    "    # but we can convert single TimeSeries by wrapping it.\n",
    "    from gwexpy.interop import from_neo, to_neo\n",
    "\n",
    "    _ = from_neo\n",
    "    _ = to_neo\n",
    "    # For single TimeSeries, we might need a Matrix wrapper or direct helper.\n",
    "    # Assuming helper exists or using Matrix:\n",
    "    from gwexpy.timeseries import TimeSeriesMatrix\n",
    "\n",
    "    tm = TimeSeriesMatrix(\n",
    "        ts.value[None, None, :], t0=ts.t0, dt=ts.dt, channel_names=[ts.name]\n",
    "    )\n",
    "    sig = tm.to_neo()\n",
    "\n",
    "    print(\"--- Neo AnalogSignal ---\")\n",
    "    print(sig)\n",
    "\n",
    "    # Display/Plot\n",
    "    plt.figure()\n",
    "    plt.plot(sig.times, sig)\n",
    "    plt.title(\"Neo AnalogSignal Plot\")\n",
    "    plt.show()\n",
    "\n",
    "    # Recover\n",
    "    tm_recovered = TimeSeriesMatrix.from_neo(sig)\n",
    "    ts_recovered = tm_recovered[0]\n",
    "    print(\"Recovered from Neo:\", ts_recovered)\n",
    "\n",
    "    del tm, tm_recovered, sig, ts_recovered\n",
    "\n",
    "except ImportError:\n",
    "    print(\"neo not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "`gwexpy` provides interoperability with a wide variety of domain-specific libraries, enabling seamless integration with existing ecosystems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
