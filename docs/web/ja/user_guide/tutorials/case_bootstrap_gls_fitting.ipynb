{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap PSD 推定と GLS フィッティング\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tatsuki-washimi/gwexpy/blob/main/docs/web/en/user_guide/tutorials/case_bootstrap_gls_fitting.ipynb)\n",
    "\n",
    "このチュートリアルでは、以下の統合的なワークフローを実演します。\n",
    "\n",
    "1. **Bootstrap PSD 推定**: VIF（分散膨張因子）およびブロック補正を用いた推定\n",
    "2. **誤差相関行列**の構築: `BifrequencyMap` を使用\n",
    "3. **一般化最小二乗法（GLS）フィッティング**: モデルパラメータの推定\n",
    "4. **MCMC との統合**: 不確かさの評価\n",
    "5. **GLS と OLS の比較**: 周波数相関を考慮することの重要性を実証\n",
    "\n",
    "## シナリオ\n",
    "\n",
    "以下の成分を含む時系列データを解析します。\n",
    "- **カラードノイズ**（べき乗則のバックグラウンド）\n",
    "- **共振ピーク**（ローレンツ型プロファイル）\n",
    "\n",
    "本チュートリアルの目的は、周波数ビン間の相関を適切に考慮した不確かさの定量化のもとで、ピークパラメータ（周波数、Q 値、振幅）を正確に推定することです。\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このチュートリアルを終えると、以下を理解できるようになります。\n",
    "- オーバーラップする FFT セグメントが周波数相関をどのように導入するか\n",
    "- Bootstrap 法が完全な共分散行列をどのように推定するか\n",
    "- 相関が存在する場合に GLS が OLS よりも優れている理由\n",
    "- ロバストな不確かさ推定のための MCMC の統合方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. セットアップとデータの準備\n",
    "\n",
    "### 1.1 インポートとパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from gwexpy.fitting import fit_series\n",
    "from gwexpy.frequencyseries import BifrequencyMap, FrequencySeries\n",
    "from gwexpy.noise.colored import power_law\n",
    "from gwexpy.noise.wave import from_asd\n",
    "from gwexpy.spectral import bootstrap_spectrogram\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation parameters\n",
    "fs = 2048.0 # Sample rate [Hz]\n",
    "duration = 256.0 # Duration [s]\n",
    "\n",
    "# Resonance peak parameters (true values)\n",
    "peak_freq = 100.0 # Resonance frequency [Hz]\n",
    "peak_Q = 20.0 # Quality factor\n",
    "peak_amplitude = 2e-21 # Peak height [1/rtHz]\n",
    "\n",
    "# Background noise parameters\n",
    "noise_exponent = 0.5 # Power-law exponent (pink noise ~ f^-0.5)\n",
    "noise_amp = 1e-22 # Noise amplitude at f_ref\n",
    "f_ref = 100.0 # Reference frequency [Hz]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 カラードノイズ + 共振ピークの生成\n",
    "\n",
    "以下の成分を含む時系列データを作成します。\n",
    "1. **バックグラウンド**: ピンクノイズ（べき乗則 ASD）\n",
    "2. **信号**: 共振ピークを表す減衰振動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate frequency array for ASD\n",
    "df = 1.0 / duration # Frequency resolution\n",
    "frequencies = np.arange(df, fs / 2, df)\n",
    "\n",
    "# Create power-law background ASD\n",
    "background_asd = power_law(\n",
    "    exponent=noise_exponent,\n",
    "    amplitude=noise_amp,\n",
    "    f_ref=f_ref,\n",
    "    frequencies=frequencies,\n",
    "    unit=\"1/Hz**(1/2)\",\n",
    "    name=\"Background ASD\",\n",
    ")\n",
    "\n",
    "# Add Lorentzian peak to the ASD\n",
    "gamma = peak_freq / peak_Q # Half-width at half-maximum\n",
    "lorentzian = peak_amplitude * (gamma / 2) ** 2 / (\n",
    "    (frequencies - peak_freq) ** 2 + (gamma / 2) ** 2\n",
    ")\n",
    "\n",
    "# Total ASD (background + peak)\n",
    "total_asd_values = np.sqrt(background_asd.value ** 2 + lorentzian ** 2)\n",
    "total_asd = FrequencySeries(\n",
    "    total_asd_values,\n",
    "    frequencies=frequencies,\n",
    "    unit=\"1/Hz**(1/2)\",\n",
    "    name=\"Total ASD\",\n",
    ")\n",
    "\n",
    "# Generate time-series from ASD\n",
    "data = from_asd(\n",
    "    total_asd,\n",
    "    duration=duration,\n",
    "    sample_rate=fs,\n",
    "    t0=0.0,\n",
    "    seed=42,\n",
    "    name=\"Colored Noise + Resonance\",\n",
    ")\n",
    "\n",
    "print(f\"Generated TimeSeries: {data}\")\n",
    "print(f\"Duration: {data.duration.value:.1f} s\")\n",
    "print(f\"Sample rate: {data.sample_rate.value:.0f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 2 seconds of the time-series\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Time-domain plot\n",
    "ax1 = axes[0]\n",
    "t_plot = data.crop(0, 2)\n",
    "ax1.plot(t_plot.times.value, t_plot.value, linewidth=0.5)\n",
    "ax1.set_xlabel(\"Time [s]\")\n",
    "ax1.set_ylabel(\"Amplitude\")\n",
    "ax1.set_title(\"Time-Series (first 2 seconds)\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Quick ASD verification\n",
    "ax2 = axes[1]\n",
    "quick_asd = data.asd(fftlength=4.0)\n",
    "ax2.loglog(quick_asd.frequencies.value, quick_asd.value, label=\"Measured ASD\", alpha=0.7)\n",
    "ax2.loglog(total_asd.frequencies.value, total_asd.value, \"--\", label=\"Input ASD\", alpha=0.7)\n",
    "ax2.axvline(peak_freq, color=\"r\", linestyle=\":\", alpha=0.5, label=f\"Peak: {peak_freq} Hz\")\n",
    "ax2.set_xlabel(\"Frequency [Hz]\")\n",
    "ax2.set_ylabel(\"ASD [1/√Hz]\")\n",
    "ax2.set_title(\"ASD Verification\")\n",
    "ax2.legend()\n",
    "ax2.set_xlim(10, 500)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. スペクトログラムの構築\n",
    "\n",
    "### 2.1 FFT パラメータ\n",
    "\n",
    "周波数分解能と統計的信頼性のバランスをとるパラメータを選択します。\n",
    "\n",
    "- **fftlength**: 周波数分解能を決定（df = 1/fftlength）\n",
    "- **stride**: スペクトログラムのビン間の時間ステップ（通常 = fftlength）\n",
    "- **overlap**: 各タイムビン内でのオーバーラップ（Welch 平均化に対して 50% 推奨）\n",
    "- **window**: Hann 窓によりスペクトル漏洩を最小化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT parameters\n",
    "fftlength = 8.0 # [s] -> df = 0.125 Hz\n",
    "overlap = 4.0 # [s] -> 50% overlap (Welch averaging within each time-bin)\n",
    "overlap_between_bins = 4.0 # [s] -> 50% overlap between time segments\n",
    "stride = fftlength - overlap_between_bins # 4.0 s effective stride\n",
    "window = \"hann\"\n",
    "\n",
    "# Calculate number of segments (approximate)\n",
    "n_segments_approx = int((duration - fftlength) / stride) + 1\n",
    "\n",
    "print(f\"FFT length: {fftlength} s\")\n",
    "print(f\"Frequency resolution: {1/fftlength:.4f} Hz\")\n",
    "print(f\"Stride (time between bins): {stride} s\")\n",
    "print(f\"Overlap between time bins: {overlap_between_bins} s ({100 * overlap_between_bins / fftlength:.0f}%)\")\n",
    "print(f\"Welch overlap (within each bin): {overlap} s ({100 * overlap / fftlength:.0f}%)\")\n",
    "print(f\"Expected time segments: ~{n_segments_approx}\")\n",
    "print(f\"Expected frequency bin correlation: ~{overlap_between_bins / fftlength:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 スペクトログラムの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spectrogram with overlapping time segments using scipy\n",
    "# This creates frequency correlations by sharing data between adjacent time bins\n",
    "\n",
    "from scipy import signal as scipy_signal\n",
    "\n",
    "# Calculate segment parameters for scipy\n",
    "\n",
    "# Generate spectrogram with scipy (allows noverlap independent of Welch averaging)\n",
    "freqs_scipy, times_scipy, Sxx_scipy = scipy_signal.spectrogram(\n",
    "    data.value,\n",
    "    fs=fs,\n",
    "    window=window,\n",
    "    nperseg=int(fftlength * fs),\n",
    "    noverlap=int(overlap_between_bins * fs),\n",
    "    scaling='density',\n",
    "    mode='psd',\n",
    "    detrend='constant',\n",
    ")\n",
    "\n",
    "# Convert to gwexpy Spectrogram object\n",
    "from astropy import units as u\n",
    "\n",
    "from gwexpy.spectrogram import Spectrogram\n",
    "\n",
    "spectrogram = Spectrogram(\n",
    "    Sxx_scipy.T, # Transpose: scipy returns (freq, time), gwpy expects (time, freq)\n",
    "    times=times_scipy * u.s,\n",
    "    frequencies=freqs_scipy * u.Hz,\n",
    "    unit=data.unit ** 2 / u.Hz,\n",
    "    name='Overlapping Spectrogram',\n",
    ")\n",
    "\n",
    "print(f\"Spectrogram shape: {spectrogram.shape}\")\n",
    "print(f\"Time bins: {spectrogram.shape[0]}\")\n",
    "print(f\"Frequency bins: {spectrogram.shape[1]}\")\n",
    "print(f\"Actual overlap: {(fftlength - overlap_between_bins) / fftlength * 100:.1f}% stride\")\n",
    "print(f\"Expected correlation from overlap: ~{overlap_between_bins / fftlength:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spectrogram\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Spectrogram plot (time-frequency)\n",
    "ax1 = axes[0]\n",
    "freq_idx = spectrogram.frequencies.value < 200\n",
    "spec_plot = spectrogram.value[:, freq_idx]\n",
    "extent = [\n",
    "    spectrogram.times.value[0],\n",
    "    spectrogram.times.value[-1],\n",
    "    spectrogram.frequencies.value[freq_idx][0],\n",
    "    spectrogram.frequencies.value[freq_idx][-1],\n",
    "]\n",
    "im = ax1.imshow(\n",
    "    np.sqrt(spec_plot.T), # Convert PSD to ASD\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    extent=extent,\n",
    "    norm=plt.matplotlib.colors.LogNorm(),\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "ax1.set_xlabel(\"Time [s]\")\n",
    "ax1.set_ylabel(\"Frequency [Hz]\")\n",
    "ax1.set_title(\"Spectrogram (ASD)\")\n",
    "plt.colorbar(im, ax=ax1, label=\"ASD [1/√Hz]\")\n",
    "\n",
    "# Time-averaged PSD\n",
    "ax2 = axes[1]\n",
    "median_psd = np.median(spectrogram.value, axis=0)\n",
    "ax2.loglog(spectrogram.frequencies.value, np.sqrt(median_psd), label=\"Median ASD\")\n",
    "ax2.axvline(peak_freq, color=\"r\", linestyle=\":\", alpha=0.5, label=f\"Peak: {peak_freq} Hz\")\n",
    "ax2.set_xlabel(\"Frequency [Hz]\")\n",
    "ax2.set_ylabel(\"ASD [1/√Hz]\")\n",
    "ax2.set_title(\"Time-Averaged ASD (Median)\")\n",
    "ax2.set_xlim(10, 500)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bootstrap PSD 推定と共分散行列\n",
    "\n",
    "### 3.1 Bootstrap を使う理由\n",
    "\n",
    "標準的な PSD 推定は周波数ビンが**独立**であることを仮定しますが、以下の場合にこの仮定は破れます。\n",
    "- セグメントが**オーバーラップ**している場合（50% オーバーラップで約 50% の相関が発生）\n",
    "- **窓関数**がスペクトルパワーを隣接ビンに拡散させる場合\n",
    "\n",
    "Bootstrap リサンプリングは以下の手順でこれらの相関を捕捉します。\n",
    "1. セグメントを復元抽出でリサンプリング\n",
    "2. 各リサンプルに対して統計量を計算\n",
    "3. 経験的共分散行列を構築\n",
    "\n",
    "### 3.2 Bootstrap パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap parameters\n",
    "n_boot = 2000 # Number of bootstrap resamples\n",
    "block_size = 4 # Block bootstrap (accounts for time correlation)\n",
    "ci = 0.68 # Confidence interval (1-sigma equivalent)\n",
    "rebin_width = None # No rebinning - preserves frequency correlations\n",
    "method = \"median\" # Bootstrap statistic\n",
    "\n",
    "print(f\"Bootstrap resamples: {n_boot}\")\n",
    "print(f\"Block size: {block_size} segments\")\n",
    "print(f\"Confidence interval: {ci * 100:.0f}%\")\n",
    "print(f\"Rebin width: {rebin_width} (no rebinning)\")\n",
    "print(\"Note: No rebinning preserves correlations but increases computation time.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Bootstrap 推定の実行\n",
    "\n",
    "`return_map=True` を指定すると、以下の両方が返されます。\n",
    "- `psd_boot`: 誤差バンド（`error_low`, `error_high`）付きの FrequencySeries\n",
    "- `cov_map`: 完全な共分散行列を含む BifrequencyMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bootstrap PSD estimation\n",
    "psd_boot, cov_map = bootstrap_spectrogram(\n",
    "    spectrogram,\n",
    "    n_boot=n_boot,\n",
    "    method=method,\n",
    "    ci=ci,\n",
    "    window=window,\n",
    "    fftlength=fftlength,\n",
    "    overlap=overlap,\n",
    "    block_size=block_size,\n",
    "    rebin_width=rebin_width,\n",
    "    return_map=True,\n",
    "    ignore_nan=True,\n",
    ")\n",
    "\n",
    "print(\"\\nBootstrap PSD:\")\n",
    "print(f\" Frequency bins: {len(psd_boot)}\")\n",
    "print(f\" Frequency range: {psd_boot.frequencies.value[0]:.2f} - {psd_boot.frequencies.value[-1]:.2f} Hz\")\n",
    "print(\"\\nCovariance Map:\")\n",
    "print(f\" Shape: {cov_map.shape}\")\n",
    "print(f\" Unit: {cov_map.unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 VIF（分散膨張因子）の検証\n",
    "\n",
    "VIF は、独立セグメントと比較して、オーバーラップするセグメントが分散をどの程度膨張させるかを定量化します。\n",
    "50% オーバーラップの Hann 窓に対して、VIF は約 1.89 です（Percival & Walden 1993, Eq. 56）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwexpy.spectral.estimation import calculate_correlation_factor\n",
    "\n",
    "# Calculate theoretical VIF for Welch averaging with 50% overlap\n",
    "# This accounts for the correlation between overlapping FFTs within each time-bin\n",
    "vif = calculate_correlation_factor(\n",
    "    window=window,\n",
    "    nperseg=int(fftlength * fs),\n",
    "    noverlap=int(overlap * fs),\n",
    "    n_blocks=int(stride / (fftlength - overlap)) + 1, # Number of FFTs per time-bin\n",
    ")\n",
    "\n",
    "print(f\"Theoretical VIF: {vif:.3f}\")\n",
    "print(\"Expected for 50% Hann overlap: ~1.89\")\n",
    "print(f\"\\nInterpretation: Variance is inflated by factor of {vif:.2f} due to overlap in Welch averaging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Bootstrap 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. PSD with error bands\n",
    "ax1 = axes[0, 0]\n",
    "freqs = psd_boot.frequencies.value\n",
    "ax1.loglog(freqs, np.sqrt(psd_boot.value), \"b-\", linewidth=1, label=\"Bootstrap PSD\")\n",
    "ax1.fill_between(\n",
    "    freqs,\n",
    "    np.sqrt(psd_boot.error_low.value),\n",
    "    np.sqrt(psd_boot.error_high.value),\n",
    "    alpha=0.3,\n",
    "    color=\"blue\",\n",
    "    label=f\"{ci*100:.0f}% CI\",\n",
    ")\n",
    "ax1.axvline(peak_freq, color=\"r\", linestyle=\":\", alpha=0.5)\n",
    "ax1.set_xlabel(\"Frequency [Hz]\")\n",
    "ax1.set_ylabel(\"ASD [1/√Hz]\")\n",
    "ax1.set_title(\"Bootstrap PSD with Error Band\")\n",
    "ax1.set_xlim(10, 500)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Relative errors\n",
    "ax2 = axes[0, 1]\n",
    "diag_var = np.diag(cov_map.value)\n",
    "diag_std = np.sqrt(np.maximum(diag_var, 0))\n",
    "relative_error = diag_std / psd_boot.value * 100 # Percentage\n",
    "ax2.semilogx(freqs, relative_error)\n",
    "ax2.axvline(peak_freq, color=\"r\", linestyle=\":\", alpha=0.5)\n",
    "ax2.set_xlabel(\"Frequency [Hz]\")\n",
    "ax2.set_ylabel(\"Relative Error [%]\")\n",
    "ax2.set_title(\"Diagonal Errors (Standard Deviation)\")\n",
    "ax2.set_xlim(10, 500)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Covariance matrix (log scale)\n",
    "ax3 = axes[1, 0]\n",
    "cov_abs = np.abs(cov_map.value)\n",
    "cov_abs[cov_abs == 0] = np.nan # Avoid log(0)\n",
    "im3 = ax3.imshow(\n",
    "    cov_abs,\n",
    "    norm=plt.matplotlib.colors.LogNorm(),\n",
    "    cmap=\"viridis\",\n",
    "    aspect=\"auto\",\n",
    "    extent=[freqs[0], freqs[-1], freqs[-1], freqs[0]],\n",
    ")\n",
    "ax3.set_xlabel(\"Frequency 1 [Hz]\")\n",
    "ax3.set_ylabel(\"Frequency 2 [Hz]\")\n",
    "ax3.set_title(\"Covariance Matrix (|Cov|, log scale)\")\n",
    "plt.colorbar(im3, ax=ax3, label=\"|Covariance|\")\n",
    "\n",
    "# 4. Correlation matrix (zoomed near peak)\n",
    "ax4 = axes[1, 1]\n",
    "# Convert covariance to correlation\n",
    "std_outer = np.outer(diag_std, diag_std)\n",
    "std_outer[std_outer == 0] = 1 # Avoid division by zero\n",
    "corr_matrix = cov_map.value / std_outer\n",
    "\n",
    "# Zoom to region around peak\n",
    "zoom_range = (peak_freq - 20, peak_freq + 20)\n",
    "zoom_mask = (freqs >= zoom_range[0]) & (freqs <= zoom_range[1])\n",
    "corr_zoom = corr_matrix[np.ix_(zoom_mask, zoom_mask)]\n",
    "freqs_zoom = freqs[zoom_mask]\n",
    "\n",
    "im4 = ax4.imshow(\n",
    "    corr_zoom,\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    aspect=\"auto\",\n",
    "    extent=[freqs_zoom[0], freqs_zoom[-1], freqs_zoom[-1], freqs_zoom[0]],\n",
    ")\n",
    "ax4.set_xlabel(\"Frequency 1 [Hz]\")\n",
    "ax4.set_ylabel(\"Frequency 2 [Hz]\")\n",
    "ax4.set_title(f\"Correlation Matrix (near {peak_freq} Hz peak)\")\n",
    "plt.colorbar(im4, ax=ax4, label=\"Correlation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# === Correlation Verification ===\n",
    "print(\"\\n=== Correlation Verification ===\")\n",
    "\n",
    "# Extract lag-1 correlations\n",
    "n_bins = corr_matrix.shape[0]\n",
    "lag1_correlations = [\n",
    "    corr_matrix[i, i+1]\n",
    "    for i in range(n_bins - 1)\n",
    "    if np.isfinite(corr_matrix[i, i+1])\n",
    "]\n",
    "\n",
    "mean_lag1 = np.mean(lag1_correlations)\n",
    "std_lag1 = np.std(lag1_correlations)\n",
    "\n",
    "print(f\"Mean correlation (adjacent bins): {mean_lag1:.3f} ± {std_lag1:.3f}\")\n",
    "print(\"Target correlation: ~0.2\")\n",
    "print(f\"Range: [{np.min(lag1_correlations):.3f}, {np.max(lag1_correlations):.3f}]\")\n",
    "\n",
    "if 0.15 <= mean_lag1 <= 0.30:\n",
    "    print(\"✓ Target correlation achieved!\")\n",
    "else:\n",
    "    print(\"⚠ Correlation outside target range\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**主な観察結果:**\n",
    "- 隣接する周波数ビンは、50% の時間セグメントオーバーラップにより**約 0.25 の相関**を示す\n",
    "- 相関行列は**帯状対角構造**（距離とともに減衰）を示す\n",
    "- リビニングなしでは、隣接ビン間の相関が保存される\n",
    "- Bootstrap はこの相関を共分散行列に反映する\n",
    "- GLS フィッティングは相関を**活用**し、OLS は相関を**無視**する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. モデル定義と GLS フィッティング\n",
    "\n",
    "### 4.1 PSD モデルの定義\n",
    "\n",
    "以下の成分からなるモデルをフィットします。\n",
    "- **べき乗則バックグラウンド**: $A_{bg} (f/f_{ref})^{\\alpha}$\n",
    "- **ローレンツ型ピーク**: $A_{peak} \\frac{(\\gamma/2)^2}{(f-f_0)^2 + (\\gamma/2)^2}$（ただし $\\gamma = f_0/Q$）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psd_model(f, A_bg, alpha, A_peak, f0, Q):\n",
    "    \"\"\"\n",
    "    PSD model: Power-law background + Lorentzian peak.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : array\n",
    "        Frequency [Hz]\n",
    "    A_bg : float\n",
    "        Background PSD amplitude at f_ref=100 Hz\n",
    "    alpha : float\n",
    "        Power-law exponent (negative for red noise)\n",
    "    A_peak : float\n",
    "        Peak PSD amplitude\n",
    "    f0 : float\n",
    "        Resonance frequency [Hz]\n",
    "    Q : float\n",
    "        Quality factor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    psd : array\n",
    "        Model PSD values\n",
    "    \"\"\"\n",
    "    f_ref = 100.0\n",
    "    background = A_bg * (f / f_ref) ** alpha\n",
    "    gamma = f0 / Q\n",
    "    lorentzian = A_peak * (gamma / 2) ** 2 / ((f - f0) ** 2 + (gamma / 2) ** 2)\n",
    "    return background + lorentzian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 フィッティング用データの準備\n",
    "\n",
    "ピーク周辺の周波数範囲にクロップし、対応する共分散部分行列を準備します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "\n",
    "# Frequency range for fitting\n",
    "freq_min, freq_max = 60, 150\n",
    "\n",
    "# Crop PSD to fitting range\n",
    "psd_fit = psd_boot.crop(freq_min, freq_max)\n",
    "freq_vals = psd_fit.frequencies.value\n",
    "\n",
    "# Find matching indices in covariance matrix\n",
    "# Use psd_fit frequencies to find corresponding indices in cov_map\n",
    "cov_freqs = cov_map.frequency1.value\n",
    "\n",
    "# Find indices that match psd_fit frequencies (within tolerance)\n",
    "indices = []\n",
    "for f in freq_vals:\n",
    "    idx = np.argmin(np.abs(cov_freqs - f))\n",
    "    indices.append(idx)\n",
    "indices = np.array(indices)\n",
    "\n",
    "# Extract covariance sub-matrix\n",
    "cov_cropped = cov_map.value[np.ix_(indices, indices)]\n",
    "\n",
    "# Verify dimensions match\n",
    "print(f\"PSD frequency bins: {len(freq_vals)}\")\n",
    "print(f\"Covariance indices: {len(indices)}\")\n",
    "\n",
    "# Create BifrequencyMap for the cropped region\n",
    "cov_fit = BifrequencyMap.from_points(\n",
    "    cov_cropped,\n",
    "    f2=u.Quantity(freq_vals, unit=\"Hz\"),\n",
    "    f1=u.Quantity(freq_vals, unit=\"Hz\"),\n",
    "    unit=cov_map.unit,\n",
    "    name=\"Cropped Covariance\",\n",
    ")\n",
    "\n",
    "print(f\"Fitting range: {freq_min} - {freq_max} Hz\")\n",
    "print(f\"Number of frequency bins: {len(psd_fit)}\")\n",
    "print(f\"Covariance matrix shape: {cov_fit.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 初期パラメータの推定値と範囲\n",
    "\n",
    "適切な初期推定値を設定することで、最適化が正しい最小値に収束しやすくなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameter values (for reference)\n",
    "true_params = {\n",
    "    \"A_bg\": noise_amp ** 2, # PSD = ASD^2\n",
    "    \"alpha\": -2 * noise_exponent, # PSD exponent = -2 * ASD exponent\n",
    "    \"A_peak\": peak_amplitude ** 2, # PSD peak height\n",
    "    \"f0\": peak_freq,\n",
    "    \"Q\": peak_Q,\n",
    "}\n",
    "\n",
    "print(\"True parameters (for validation):\")\n",
    "for k, v in true_params.items():\n",
    "    print(f\" {k}: {v:.3e}\" if v < 0.01 else f\" {k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guesses (slightly offset from true values)\n",
    "p0 = {\n",
    "    \"A_bg\": 1.5e-44, # Start somewhat close\n",
    "    \"alpha\": -0.8,\n",
    "    \"A_peak\": 5e-42,\n",
    "    \"f0\": 98.0,\n",
    "    \"Q\": 15.0,\n",
    "}\n",
    "\n",
    "# Parameter bounds\n",
    "bounds = {\n",
    "    \"A_bg\": (1e-46, 1e-42),\n",
    "    \"alpha\": (-3, 0),\n",
    "    \"A_peak\": (1e-44, 1e-40),\n",
    "    \"f0\": (90, 110),\n",
    "    \"Q\": (5, 50),\n",
    "}\n",
    "\n",
    "print(\"Initial guesses:\")\n",
    "for k, v in p0.items():\n",
    "    print(f\" {k}: {v:.3e}\" if abs(v) < 0.01 else f\" {k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 GLS フィッティングの実行\n",
    "\n",
    "`cov=BifrequencyMap` を渡すことで、`fit_series` は完全な共分散構造を考慮した**一般化最小二乗法（GLS）**を自動的に使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLS fit using full covariance matrix\n",
    "result_gls = fit_series(\n",
    "    psd_fit,\n",
    "    psd_model,\n",
    "    cov=cov_fit,\n",
    "    p0=p0,\n",
    "    limits=bounds,\n",
    ")\n",
    "\n",
    "print(\"GLS Fit Results:\")\n",
    "print(\"=\" * 50)\n",
    "display(result_gls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 フィッティング結果の解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters and errors\n",
    "params_gls = result_gls.params\n",
    "errors_gls = result_gls.errors\n",
    "\n",
    "print(\"\\nParameter Comparison (GLS Fit):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Parameter':<10} {'Fitted':<15} {'Error':<12} {'True':<15} {'Pull':>8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name in params_gls.keys():\n",
    "    fitted = params_gls[name]\n",
    "    error = errors_gls[name]\n",
    "    true = true_params[name]\n",
    "    pull = (fitted - true) / error if error > 0 else 0\n",
    "\n",
    "    if abs(fitted) < 0.01:\n",
    "        print(f\"{name:<10} {fitted:<15.3e} {error:<12.3e} {true:<15.3e} {pull:>8.2f}\")\n",
    "    else:\n",
    "        print(f\"{name:<10} {fitted:<15.4f} {error:<12.4f} {true:<15.4f} {pull:>8.2f}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nχ²/ndof = {result_gls.chi2:.1f} / {result_gls.ndof} = {result_gls.reduced_chi2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fit results\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True, gridspec_kw={\"height_ratios\": [3, 1]})\n",
    "\n",
    "# 1. Data and fit\n",
    "ax1 = axes[0]\n",
    "\n",
    "# Data with error bars (from diagonal of covariance)\n",
    "diag_err = np.sqrt(np.maximum(np.diag(cov_fit.value), 0))\n",
    "ax1.errorbar(\n",
    "    freq_vals, psd_fit.value, yerr=diag_err,\n",
    "    fmt=\"o\", markersize=3, alpha=0.6, label=\"Data\", capsize=2,\n",
    ")\n",
    "\n",
    "# Best-fit model\n",
    "f_model = np.linspace(freq_min, freq_max, 500)\n",
    "y_model = psd_model(f_model, **params_gls)\n",
    "ax1.plot(f_model, y_model, \"r-\", linewidth=2, label=\"GLS Fit\")\n",
    "\n",
    "# True model for comparison\n",
    "y_true = psd_model(f_model, **true_params)\n",
    "ax1.plot(f_model, y_true, \"g--\", linewidth=1.5, alpha=0.7, label=\"True Model\")\n",
    "\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel(\"PSD [1/Hz]\")\n",
    "ax1.set_title(\"GLS Fit: Power-Law Background + Lorentzian Peak\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Normalized residuals\n",
    "ax2 = axes[1]\n",
    "y_fit_at_data = psd_model(freq_vals, **params_gls)\n",
    "residuals = (psd_fit.value - y_fit_at_data) / diag_err\n",
    "ax2.scatter(freq_vals, residuals, s=10, alpha=0.7)\n",
    "ax2.axhline(0, color=\"r\", linestyle=\"-\", linewidth=1)\n",
    "ax2.axhline(2, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax2.axhline(-2, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax2.set_xlabel(\"Frequency [Hz]\")\n",
    "ax2.set_ylabel(\"Residual / σ\")\n",
    "ax2.set_ylim(-4, 4)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MCMC による不確かさの評価\n",
    "\n",
    "MCMC（マルコフ連鎖モンテカルロ法）は、パラメータの不確かさと相関のより頑健な推定を提供します。\n",
    "\n",
    "### 5.1 MCMC の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC parameters\n",
    "n_walkers = 32\n",
    "n_steps = 3000\n",
    "burn_in = 500\n",
    "\n",
    "print(f\"Running MCMC with {n_walkers} walkers, {n_steps} steps...\")\n",
    "print(f\"Burn-in: {burn_in} steps\")\n",
    "\n",
    "try:\n",
    "    sampler = result_gls.run_mcmc(\n",
    "        n_walkers=n_walkers,\n",
    "        n_steps=n_steps,\n",
    "        burn_in=burn_in,\n",
    "        progress=True,\n",
    "    )\n",
    "    mcmc_available = True\n",
    "except ImportError as e:\n",
    "    print(f\"MCMC requires 'emcee' package: {e}\")\n",
    "    mcmc_available = False\n",
    "except Exception as e:\n",
    "    print(f\"MCMC error: {e}\")\n",
    "    mcmc_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 収束診断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mcmc_available:\n",
    "    # Acceptance fraction\n",
    "    acc_frac = np.mean(sampler.acceptance_fraction)\n",
    "    print(\"\\nMCMC Diagnostics:\")\n",
    "    print(f\" Mean acceptance fraction: {acc_frac:.3f}\")\n",
    "    print(\" (Optimal range: 0.2 - 0.5)\")\n",
    "\n",
    "    # Autocorrelation time (if enough samples)\n",
    "    try:\n",
    "        tau = sampler.get_autocorr_time(quiet=True)\n",
    "        print(\"\\n Autocorrelation times:\")\n",
    "        for i, name in enumerate(params_gls.keys()):\n",
    "            print(f\" {name}: {tau[i]:.1f} steps\")\n",
    "        print(f\" Effective samples: ~{n_steps / np.max(tau):.0f}\")\n",
    "    except Exception:\n",
    "        print(\" (Autocorrelation time estimation requires more samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 コーナープロットとトレースプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mcmc_available:\n",
    "    # Corner plot\n",
    "    try:\n",
    "        result_gls.plot_corner(\n",
    "            truths=list(true_params.values()),\n",
    "            quantiles=[0.16, 0.5, 0.84],\n",
    "            show_titles=True,\n",
    "        )\n",
    "        plt.suptitle(\"MCMC Posterior Distributions (GLS)\", y=1.02)\n",
    "        plt.show()\n",
    "    except ImportError:\n",
    "        print(\"Corner plot requires 'corner' package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mcmc_available:\n",
    "    # Trace plots\n",
    "    samples = sampler.get_chain() # Shape: (n_steps, n_walkers, n_params)\n",
    "    param_names = list(params_gls.keys())\n",
    "\n",
    "    fig, axes = plt.subplots(len(param_names), 1, figsize=(12, 2.5 * len(param_names)), sharex=True)\n",
    "\n",
    "    for i, (ax, name) in enumerate(zip(axes, param_names)):\n",
    "        for j in range(min(10, n_walkers)): # Plot subset of walkers\n",
    "            ax.plot(samples[:, j, i], alpha=0.3, linewidth=0.5)\n",
    "        ax.axhline(true_params[name], color=\"r\", linestyle=\"--\", label=\"True\")\n",
    "        ax.axvline(burn_in, color=\"gray\", linestyle=\":\", alpha=0.5, label=\"Burn-in\")\n",
    "        ax.set_ylabel(name)\n",
    "        if i == 0:\n",
    "            ax.legend(loc=\"upper right\")\n",
    "\n",
    "    axes[-1].set_xlabel(\"Step\")\n",
    "    plt.suptitle(\"MCMC Trace Plots\", y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GLS と OLS の比較\n",
    "\n",
    "### 6.1 OLS フィッティングの実行（対角共分散のみ）\n",
    "\n",
    "OLS（通常最小二乗法）は非対角相関を無視し、対角分散のみを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diagonal-only covariance (for OLS)\n",
    "diag_variances = np.diag(cov_fit.value)\n",
    "cov_diag_matrix = np.diag(diag_variances)\n",
    "\n",
    "cov_ols = BifrequencyMap.from_points(\n",
    "    cov_diag_matrix,\n",
    "    f2=cov_fit.frequency2,\n",
    "    f1=cov_fit.frequency1,\n",
    "    unit=cov_fit.unit,\n",
    "    name=\"Diagonal Covariance (OLS)\",\n",
    ")\n",
    "\n",
    "# OLS fit\n",
    "result_ols = fit_series(\n",
    "    psd_fit,\n",
    "    psd_model,\n",
    "    cov=cov_ols,\n",
    "    p0=p0,\n",
    "    limits=bounds,\n",
    ")\n",
    "\n",
    "print(\"OLS Fit Results:\")\n",
    "print(\"=\" * 50)\n",
    "display(result_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 GLS と OLS の結果比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ols = result_ols.params\n",
    "errors_ols = result_ols.errors\n",
    "\n",
    "print(\"\\nGLS vs OLS Comparison:\")\n",
    "print(\"=\" * 85)\n",
    "print(f\"{'Parameter':<10} {'GLS Value':<14} {'GLS Error':<12} {'OLS Value':<14} {'OLS Error':<12} {'Ratio':>8}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "error_ratios = []\n",
    "for name in params_gls.keys():\n",
    "    gls_val = params_gls[name]\n",
    "    gls_err = errors_gls[name]\n",
    "    ols_val = params_ols[name]\n",
    "    ols_err = errors_ols[name]\n",
    "    ratio = gls_err / ols_err if ols_err > 0 else float('inf')\n",
    "    error_ratios.append((name, ratio))\n",
    "\n",
    "    if abs(gls_val) < 0.01:\n",
    "        print(f\"{name:<10} {gls_val:<14.3e} {gls_err:<12.3e} {ols_val:<14.3e} {ols_err:<12.3e} {ratio:>8.2f}\")\n",
    "    else:\n",
    "        print(f\"{name:<10} {gls_val:<14.4f} {gls_err:<12.4f} {ols_val:<14.4f} {ols_err:<12.4f} {ratio:>8.2f}\")\n",
    "\n",
    "print(\"-\" * 85)\n",
    "print(f\"\\nχ²/ndof: GLS = {result_gls.reduced_chi2:.3f} OLS = {result_ols.reduced_chi2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize error ratio comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "names = [r[0] for r in error_ratios]\n",
    "ratios = [r[1] for r in error_ratios]\n",
    "\n",
    "x = np.arange(len(names))\n",
    "bars = ax.bar(x, ratios, color=\"steelblue\", edgecolor=\"black\")\n",
    "\n",
    "# Add reference line at ratio=1\n",
    "ax.axhline(1.0, color=\"r\", linestyle=\"--\", linewidth=2, label=\"Ratio = 1 (Equal)\")\n",
    "\n",
    "ax.set_xlabel(\"Parameter\")\n",
    "ax.set_ylabel(\"Error Ratio (GLS / OLS)\")\n",
    "ax.set_title(\"Parameter Uncertainty: GLS vs OLS\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Annotate bars\n",
    "for bar, ratio in zip(bars, ratios):\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.02,\n",
    "        f\"{ratio:.2f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 重要な知見\n",
    "\n",
    "**GLS の誤差は一般的に OLS の誤差よりも大きくなります。** その理由は以下の通りです。\n",
    "\n",
    "1. **OLS は不確かさを過小評価**する（隣接ビン間の正の相関を無視するため）\n",
    "2. **GLS は有効自由度の減少を適切に考慮**する\n",
    "3. 誤差比（GLS/OLS > 1）は**相関の真の影響**を反映する\n",
    "\n",
    "**約 0.25 の相関が存在する場合の期待値**: GLS 誤差は OLS より 10-30% 大きくなる\n",
    "\n",
    "**GLS が OLS と異なる理由**:\n",
    "1. OLS は独立性を仮定 → 不確かさを過小評価\n",
    "2. GLS は相関を考慮 → 有効自由度を削減\n",
    "3. 誤差比（GLS/OLS）は相関の影響を定量化\n",
    "4. 50% オーバーラップの場合: 約 0.25 の相関が GLS と OLS の間に有意な差をもたらす\n",
    "\n",
    "**実用上の示唆:**\n",
    "- OLS は過信した（小さすぎる）誤差バーを生成する可能性がある\n",
    "- GLS はより正直な不確かさの推定を提供する\n",
    "- 精密測定においては GLS が不可欠である\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. まとめとベストプラクティス\n",
    "\n",
    "### 主なポイント\n",
    "\n",
    "1. **Bootstrap PSD 推定**はスペクトルとその完全な共分散行列の両方を提供する\n",
    "2. **オーバーラップするセグメント**は標準的な手法では無視される相関を導入する\n",
    "3. **GLS フィッティング**は共分散構造に基づいてデータを適切に重み付けする\n",
    "4. **MCMC** は複雑なモデルに対してロバストな事後分布を提供する\n",
    "5. **OLS は相関が存在する場合に誤差を過小評価**する\n",
    "\n",
    "### 推奨ワークフロー\n",
    "\n",
    "```python\n",
    "# 1. スペクトログラムの生成\n",
    "stride = fftlength - overlap\n",
    "spectrogram = data.spectrogram(stride=stride, fftlength=fftlength, overlap=overlap, window='hann')\n",
    "\n",
    "# 2. 共分散行列付き Bootstrap\n",
    "psd, cov = bootstrap_spectrogram(spectrogram, return_map=True, ...)\n",
    "\n",
    "# 3. GLS フィッティング\n",
    "result = fit_series(psd, model, cov=cov, p0=..., limits=...)\n",
    "\n",
    "# 4. ロバストな不確かさのための MCMC\n",
    "result.run_mcmc(n_walkers=32, n_steps=5000)\n",
    "result.plot_corner()\n",
    "```\n",
    "\n",
    "### よくある落とし穴\n",
    "\n",
    "- **相関のあるデータに OLS を使用**する → 誤差の過小評価\n",
    "- **Bootstrap サンプル数が少なすぎる** → 共分散推定にノイズが混入\n",
    "- **初期推定値が不適切** → 局所最小値に収束する可能性\n",
    "- **共分散のクロップを忘れる** → 次元の不一致エラー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 付録: BifrequencyMap の操作\n",
    "\n",
    "`BifrequencyMap` の一般的な操作のクイックリファレンスです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example BifrequencyMap operations\n",
    "\n",
    "# 1. Get inverse (for manual GLS)\n",
    "cov_inv = cov_fit.inverse()\n",
    "print(f\"Inverse shape: {cov_inv.shape}\")\n",
    "print(f\"Inverse unit: {cov_inv.unit}\")\n",
    "\n",
    "# 2. Extract diagonal (variances)\n",
    "variances = np.diag(cov_fit.value)\n",
    "std_devs = np.sqrt(np.maximum(variances, 0))\n",
    "print(f\"\\nDiagonal extracted: {len(variances)} values\")\n",
    "\n",
    "# 3. Compute correlation matrix\n",
    "std_outer = np.outer(std_devs, std_devs)\n",
    "std_outer[std_outer == 0] = 1\n",
    "correlation = cov_fit.value / std_outer\n",
    "print(f\"Correlation range: [{correlation.min():.3f}, {correlation.max():.3f}]\")\n",
    "\n",
    "# 4. Create from scratch\n",
    "n = 10\n",
    "test_cov = np.eye(n) + 0.1 * np.ones((n, n)) # Diagonal + small off-diagonal\n",
    "test_freqs = np.arange(n) * 1.0 + 50.0\n",
    "test_map = BifrequencyMap.from_points(\n",
    "    test_cov,\n",
    "    f2=test_freqs,\n",
    "    f1=test_freqs,\n",
    "    unit=\"Hz^-2\",\n",
    "    name=\"Test Covariance\",\n",
    ")\n",
    "print(f\"\\nCreated test BifrequencyMap: {test_map.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 参考文献\n",
    "\n",
    "- **Percival & Walden (1993)**: Spectral Analysis for Physical Applications - VIF の導出\n",
    "- **gwexpy API**: [Spectral module](../../reference/api/spectral.rst), [Fitting module](../../reference/api/fitting.rst)\n",
    "- **関連チュートリアル**: [Advanced Fitting](advanced_fitting.ipynb), [Noise Budget](case_noise_budget.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwexpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
