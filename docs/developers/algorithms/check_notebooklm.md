**gwexpy アルゴリズム検証レポート**  
**担当:** 上級物理学者兼ソフトウェア監査人**対象:** gwexpy パッケージ内カスタムアルゴリズム実装**参照:** 提供されたアルゴリズムコンテキストおよび機能説明書 1-150  
ご提示いただいた gwexpy のアルゴリズムコンテキストに基づき、物理的妥当性、統計的厳密性、および数値的安定性の観点から監査を行いました。以下に検証結果を報告します。

### 1\. 物理場と波数空間 (Physical Fields & k-space)

* **Severity (重要度):** High (物理的定義の不整合リスク)  
* **Finding (指摘事項):**ScalarField.fft\_space における座標変換ロジックにおいて、np.fft.fftfreq 等の標準ライブラリは通常「空間周波数 $f\_x$ (cycles/unit)」を返します。しかし、物理学における波数 $k$ は通常 $k \= 2\\pi f\_x$ (rad/unit) で定義されます 2。もし実装が $2\\pi$ の係数を乗算せずに fftfreq の出力をそのまま $k$ として扱っている場合、波動方程式や分散関係の解析において $2\\pi$ 倍のスケールエラーが発生します。また、単位変換（例: m $\\to$ 1/m vs rad/m）が astropy.units 等で明示的に処理されていない場合、後続の物理計算で次元不整合が生じます。  
* **Recommendation (推奨):**波数ベクトルの生成ロジックが以下の定義に従っているか確認し、必要に応じて修正してください。$$ k \= 2\\pi \\cdot \\text{fftfreq}(N, d) $$また、返り値の単位オブジェクトが 1/m (サイクル) なのか rad/m (角波数) なのかを明示的に区別するメタデータ管理を追加することを推奨します。

### 2\. 過渡応答解析 (Transient Response Analysis)

* **Severity (重要度):** Medium (振幅精度の低下)  
* **Finding (指摘事項):**\_fft\_transient および ResponseFunctionAnalysis において、過渡信号（ステップ応答等）に対してゼロパディング（zero-padding）を行う際、エネルギー保存則または振幅密度の正規化に注意が必要です 2。通常のFFTは信号が周期的であることを仮定します。過渡信号に対してゼロパディングを行うと、周波数ビン幅 $df$ が変化します ($df \= 1/(N\_{padded} \\cdot dt)$)。この際、スペクトル振幅の正規化係数を元の信号長 $N\_{signal}$ に基づくか、パディング後の長さ $N\_{padded}$ に基づくかで、物理的な振幅値（例: $\\text{V}/\\sqrt{\\text{Hz}}$ や $\\text{V}$）が変わってしまいます。特に gwexpy がDTT（LIGO診断ツール）との整合性を謳っている場合 6、このスケーリング係数の不一致は致命的です。  
* **Recommendation (推奨):**ゼロパディング適用時の振幅補正係数を以下のように実装してください。$$ A\_{corrected} \= A\_{raw} \\cdot \\frac{N\_{padded}}{N\_{signal}} \\quad (\\text{または用途に応じた正規化}) $$過渡解析用に、パディング前後でParsevalの定理（エネルギー保存）が成立するかを検証するユニットテストを追加してください。

### 3\. ロバスト統計 (Robust Statistics)

* **Severity (重要度):** Medium (分散の過小評価)  
* **Finding (指摘事項):**bootstrap\_spectrogram における VIF (Variance Inflation Factor) 補正とブロックブートストラップのロジックについて 2。スペクトログラム計算時にオーバーラップ（重複）があるウィンドウを使用している場合、隣接する時間ビン間で強い相関が生じます。単純なブートストラップ法では、この相関構造が破壊され、誤差（分散）を過小評価するリスクがあります。また、VIF補正が単なる「サンプル数の減少」として実装されている場合、Welch法におけるウィンドウ関数の重なりによる共分散（effective degrees of freedom）を正確に反映していない可能性があります。  
* **Recommendation (推奨):**ブートストラップのリサンプリング単位（ブロック長）を、データのコヒーレンス時間またはウィンドウのオーバーラップ長よりも十分に大きく設定するロジックを強制してください。分散推定においては、以下の概念に基づく補正係数を確認してください。$$ \\text{Var}*{eff} \\approx \\text{Var}*{raw} \\cdot (1 \+ 2 \\sum \\rho(\\tau)) $$

### 4\. ベイズフィッティング (Bayesian Fitting)

* **Severity (重要度):** High (数値的安定性)  
* **Finding (指摘事項):**run\_mcmc において GLS (Generalized Least Squares) 共分散行列を用いて対数尤度 (log-likelihood) を計算する際、共分散行列 $C$ の逆行列 $C^{-1}$ を直接計算している箇所があれば、数値的に極めて不安定です 2。特に低周波ノイズ等で相関が強い場合、行列 $C$ の条件数 (condition number) が悪化し、浮動小数点誤差により尤度が発散したり、負の分散が生じるリスクがあります。計算式 $\\chi^2 \= r^T C^{-1} r$ の直接実装は避けるべきです。  
* **Recommendation (推奨):**逆行列を明示的に求めず、**コレスキー分解 (Cholesky decomposition)** を使用して線形方程式を解く形式に変更してください。$$ C \= L L^T, \\quad \\text{solve } L x \= r, \\quad \\chi^2 \= |x|^2 $$また、対数行列式 $\\log(\\det(C))$ の計算も 2 \* sum(log(diag(L))) としてコレスキー因子から求めてください。

### 5\. 時系列モデリング (Time Series Modeling)

* **Severity (重要度):** Low (時間精度のドリフト)  
* **Finding (指摘事項):**ARIMAモデルの結果を GPS時刻を持つ TimeSeries オブジェクトにマッピングする際 2、浮動小数点演算による時刻ドリフトのリスクがあります。ARIMAの実装（statsmodels等）は通常、整数のインデックス（ステップ数）で動作します。これを t0 \+ n \* dt としてGPS時刻に戻す際、dt が小さい、かつデータ長が長い場合（例: 高サンプリングレートの長時間データ）、倍精度浮動小数点数であっても末尾でマイクロ秒オーダーのズレが生じる可能性があります。これは重力波解析等の高精度な位相合わせが必要な場面で問題となります。  
* **Recommendation (推奨):**時間の再構成には、累積誤差を防ぐために astropy.time.Time または整数演算（ナノ秒単位のカウント等）を用いた高精度な時刻配列生成ロジックを使用してください。np.arange(N) \* dt ではなく linspace や高精度ラッパーを使用することを推奨します。

### 6\. 次元削減 (Dimensionality Reduction)

* **Severity (重要度):** Medium (構造情報の喪失)  
* **Finding (指摘事項):**3次元構造を持つ TimeSeriesMatrix (例: Channels, Rows, Time) を PCA/ICA のために平坦化 (flatten) する際 2、次元の順序（Order）が物理的解釈に直結します。もし (Time, Channels \* Rows) 以外の形状（例: 時間次元を混ぜてしまう）で平坦化を行うと、PCAは空間的な相関ではなく、時間的な自己相関を抽出してしまい、物理的なモード分解（センサー間のコヒーレントなノイズ等）として機能しなくなります。また、再構築（inverse transform）時に元の形状 (Rows, Cols) に戻すロジックがメタデータと整合していないと、データの転置エラーが発生します。  
* **Recommendation (推奨):**平坦化の際は、必ず「サンプル次元 \= 時間」「特徴量次元 \= 物理チャンネル」となるように reshape または transpose を明示的に行ってください。$$ X\_{2D} \= \\text{reshape}(X\_{3D}, (\\text{Time}, \\text{Channels} \\times \\text{Rows})) $$また、特異値分解後の再構築時に、元のメタデータ（チャンネル名や空間配置）が正しい順序で復元されるか検証するアサーションを追加してください。

**監査人署名:** Senior Physicist / Software Auditor  


提示されたソースコードの概要および機能リストを詳細に再調査した結果、当初の6点以外にも、物理的・数値的に検証を要する重要な独自アルゴリズムが複数確認されました。

特に、非線形・非定常信号解析（HHT/EMD）や、数千チャンネル規模の相関解析（Bruco）、およびラプラス変換の実装において、潜在的なリスクが見受けられます。以下に追加の検証報告を提出します。

---

### **追加検証報告書 (Addendum Validation Report)**

### 7. ヒルベルト・ファン変換 (HHT: Hilbert-Huang Transform)

*   **Context:** `gwexpy/timeseries/_spectral_special.py`, `Hilbert-Huang Transform (HHT/EMD)`,,
*   **Severity:** **High** (物理的解釈の妥当性)
*   **Finding (指摘事項):**
    経験的モード分解 (EMD) およびヒルベルトスペクトル解析の実装において、以下の2点が懸念されます。
    1.  **端点効果 (End Effects):** EMDの篩い分け (sifting) プロセスで使用されるスプライン補間は、データ両端で発散または大きな誤差を生じやすい特性があります。これが「固有モード関数 (IMF)」の形状を歪め、偽の低周波成分を生成するリスクがあります。
    2.  **瞬時周波数の特異点:** 解析信号の位相 $\theta(t)$ を微分して瞬時周波数 $\omega(t) = d\theta/dt$ を求める際、振幅がゼロに近い点やノイズの影響で $\omega(t)$ が負の値になったり、物理的に無意味な高周波スパイクが発生したりすることがあります。
*   **Recommendation (推奨):**
    *   データの両端に対して、**鏡像法 (Mirror Extension)** または予測パディングを適用して端点効果を抑制する処理が含まれているか確認してください。
    *   瞬時周波数の計算において、平滑化微分（Savitzky-Golayフィルタ等）または `Nakamura's method` (正規化ヒルベルト変換) を適用し、負の周波数を除外するロジックを実装してください。

### 8. 短時間ラプラス変換 (STLT: Short-Time Laplace Transform)

*   **Context:** `Short-Time Laplace Transform (STLT)`,
*   **Severity:** **High** (数値的安定性 / オーバーフロー)
*   **Finding (指摘事項):**
    減衰解析のためにラプラス変換カーネル $K(s, t) = e^{-st} = e^{-(\sigma + i\omega)t}$ を使用していると思われます。
    実数部 $\sigma$（減衰/成長率）の符号と時間の長さに依存して、項 $e^{-\sigma t}$ は指数関数的に増大（オーバーフロー）または減少（アンダーフロー）します。特に、長い時系列データに対して $\sigma < 0$ （不安定極の解析など）を設定して単純に積和演算を行うと、浮動小数点数の範囲を容易に超えます。
*   **Recommendation (推奨):**
    数値計算においては、対数領域での計算 (`log-sum-exp` トリック) を検討するか、あるいは計算時間を短いブロックに分割し、各ブロック内で $t$ をリセットしてスケーリングを行うことで、指数の爆発を防ぐアルゴリズムを採用してください。
    $$ \int e^{-\sigma t} x(t) e^{-i\omega t} dt \approx \sum_k e^{-\sigma t_k} \text{FFT}(x[k]) $$
    上記のように、FFT適用前の窓関数として $\sigma$ を扱う際のスケーリング管理を徹底してください。

### 9. 大規模コヒーレンス探索エンジン (Bruco / Fast Coherence)

*   **Context:** `gwexpy/analysis/bruco.py`, `Optimized Welch coherence calculation for thousands of auxiliary channels`,,
*   **Severity:** **Medium** (統計的有意性の過大評価)
*   **Finding (指摘事項):**
    数千の補助チャンネルに対してコヒーレンス計算を最適化しているとありますが、大量のチャンネルをスキャンする場合、**多重比較問題 (Look-elsewhere effect)** が発生します。
    通常の閾値（例: 95%信頼区間）を使用すると、チャンネル数が $N=1000$ の場合、ノイズだけで偶然高いコヒーレンスを示す「偽陽性」が約50個発生することになります。単に計算速度を最適化するだけでなく、統計的な閾値補正（Bonferroni補正やFDR制御）が組み込まれていない場合、誤ったノイズ源の特定につながります。
*   **Recommendation (推奨):**
    スキャンするチャンネル数 $N_{ch}$ に応じて、有意水準 $\alpha$ を動的に補正するロジックを推奨します。
    $$ \alpha_{corrected} \approx \frac{\alpha}{N_{ch}} \quad (\text{Bonferroni}) $$
    または、計算されたコヒーレンス分布のバックグラウンド（null hypothesis）を推定し、そこからの偏差として有意性を評価する機能を実装してください。

### 10. 欠損値補完 (Imputation with Gap Constraints)

*   **Context:** `gwexpy/signal/preprocessing/imputation.py`,
*   **Severity:** **Medium** (スペクトル解析への悪影響)
*   **Finding (指摘事項):**
    「大きな時間ギャップをブリッジしない (prevents bridging large temporal gaps)」という制約付き補完は有用ですが、補完方法（線形、スプライン、ゼロ埋め）によっては、後段のFFT解析においてスペクトル漏れや、人工的なステップ関数による $1/f$ ノイズ様のアーティファクトを引き起こします。
    特に、ギャップの境界で導関数が不連続になると、高周波帯域のPSD（パワースペクトル密度）が汚染されます。
*   **Recommendation (推奨):**
    補完部分に対して、境界での滑らかさを保証するウィンドウ処理（Tapering）を適用するか、あるいは `Inpaint` 手法（ARモデルに基づくギャップフィリング）を使用することを推奨します。また、補完されたデータを含む区間には、解析時にフラグを立てるメタデータ管理が必要です。

---
**検証総括:**
上記4点（HHT, STLT, Bruco, Imputation）は、いずれも標準的なライブラリの単純利用では解決できない物理的・数学的な落とし穴を含んでいます。特にSTLTの数値安定性とHHTの端点処理は、解析結果の信頼性を根底から損なう可能性があるため、優先的なコード監査を推奨します。